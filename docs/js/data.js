// Paper data for visualization - auto-generated
window.paperData = {
  meta: {
    totalAnalyzed: 93,
    lastUpdated: '2026-01-28',
  },
  nodes: [
    {
      id: '2305.18654',
      title: 'Faith and Fate: Limits of Transformers on Compositionality',
      shortTitle: 'Faith & Fate',
      date: 'May 2023',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'Transformers solve compositional tasks via linearized subgraph matching, not genuine reasoning. Error propagation is exponential.',
      keyEvidence: [
        'ID ~100%, OOD ~0%',
        'Exponential error accumulation',
        "Grokking (60 epochs) doesn't help OOD",
      ],
    },
    {
      id: '2506.06941',
      title:
        'The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models',
      shortTitle: 'Illusion of Thinking',
      date: 'Jun 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        'LRMs face complete accuracy collapse beyond certain complexity thresholds. Three distinct performance regimes exist.',
      keyEvidence: [
        'Collapse at ~8-10 disks (Hanoi)',
        'Token usage DECREASES at collapse',
        'All LRMs fail at high complexity',
      ],
    },
    {
      id: '2410.05229',
      title: 'GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in LLMs',
      shortTitle: 'GSM-Symbolic',
      date: 'Oct 2024',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'LLMs do not perform genuine logical reasoning — they replicate reasoning steps from training data via pattern matching.',
      keyEvidence: [
        'Up to 65% drop from irrelevant info (NoOp)',
        'High variance across equivalent questions',
        'Few-shot cannot recover',
      ],
    },
    {
      id: '2506.18880',
      title: 'OMEGA: Can LLMs Reason Outside the Box in Math?',
      shortTitle: 'OMEGA',
      date: 'Jun 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'RL improves exploratory generalization but compositional and transformative generalization remain near-zero.',
      keyEvidence: [
        '>69% isolated skills → near-0% composed',
        '0% transformative generalization',
        '38% correct→incorrect from overthinking',
      ],
    },
    {
      id: '2512.07783',
      title: 'On the Interplay of Pre-Training, Mid-Training, and RL',
      shortTitle: 'Interplay',
      date: 'Dec 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "RL cannot synthesize capabilities from void; it requires latent 'seeds' to amplify. 0% exposure = RL fails; ≥1% = success.",
      keyEvidence: [
        '0% exposure → RL FAILS',
        '≥1% exposure → +60% pass@128',
        "RL only helps at 'edge of competence'",
      ],
    },
    {
      id: '2501.12948',
      title: 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL',
      shortTitle: 'DeepSeek-R1',
      date: 'Jan 2025',
      stance: 'challenges',
      cluster: 'emergence',
      coreArgument:
        "Reasoning capabilities can be incentivized through pure RL without human-labeled reasoning data. 'Aha moment' emerges spontaneously.",
      keyEvidence: [
        'AIME 79.8% (vs o1 79.2%)',
        'Emergent self-reflection behavior',
        '7B distilled > 32B QwQ',
      ],
    },
    {
      id: '2501.19393',
      title: 's1: Simple test-time scaling',
      shortTitle: 's1',
      date: 'Jan 2025',
      stance: 'challenges',
      cluster: 'mechanism',
      coreArgument:
        "Test-time scaling achievable with only 1K samples. Reasoning pre-exists in base models; SFT surfaces it, doesn't create it.",
      keyEvidence: [
        '26.7% → 50% AIME with 1K samples',
        'Budget forcing adds +7%',
        "1K samples can't TEACH AIME math",
      ],
    },
    {
      id: '2307.13702',
      title: 'Measuring Faithfulness in Chain-of-Thought Reasoning',
      shortTitle: 'Measuring Faithfulness',
      date: 'Jul 2023',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'CoT faithfulness varies dramatically by task. Larger models = less faithful. CoT can be post-hoc rationalization.',
      keyEvidence: [
        'ARC Easy: 0.02 AOC (model ignores CoT)',
        'Larger models = LESS faithful',
        "Filler tokens don't help",
      ],
    },
    {
      id: '2601.14456',
      title: 'On the Generalization Gap in LLM Planning',
      shortTitle: 'Planning Gap',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        "Fine-tuned LLMs achieve high in-domain (82.9%) but 0% on unseen domains. Verifier-reward RL doesn't improve OOD.",
      keyEvidence: [
        '82.9% ID → 0% OOD',
        '11.5pp drop from symbol anonymization',
        'Models loop without progress',
      ],
    },
    {
      id: '2601.00514',
      title: 'The Illusion of Insight in Reasoning Models',
      shortTitle: 'Illusion of Insight',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        "'Aha!' moments are rare (~2-6%), don't improve with training, and seldom help accuracy. Shifts are unstable inference, not insight.",
      keyEvidence: [
        '~2-6% shift prevalence',
        "Shifts don't increase with training",
        'Correlate with uncertainty, not insight',
      ],
    },
    {
      id: '2507.07313',
      title: 'Frontier LLMs Still Struggle with Simple Reasoning Tasks',
      shortTitle: 'Frontier Struggles',
      date: 'Jul 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        "Making problems EASIER can make models perform WORSE. 'Reasoning delirium' — models apply memorized solutions to wrong problems.",
      keyEvidence: [
        'GPT-4o: 75%→20% on unpuzzles',
        'R1 0% on character counting',
        'Every model better on context-shifted',
      ],
    },
    {
      id: '2510.18254',
      title: 'Illusions of Reflection',
      shortTitle: 'Illusions of Reflection',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        "LLM reflection repeats the SAME failure 85% of time. Reasoning models show NO advantage. 'Fluent self-critique without correction.'",
      keyEvidence: [
        '85% same-failure repeat rate',
        'Reasoning models WORSE (0.036 vs 0.111)',
        'Just retrying works as well',
      ],
    },
    {
      id: '2402.10200',
      title: 'Chain-of-Thought Reasoning Without Prompting',
      shortTitle: 'CoT Without Prompting',
      date: 'Feb 2024',
      stance: 'challenges',
      cluster: 'mechanism',
      coreArgument:
        'CoT reasoning paths exist inherently in pre-trained LLMs, hidden by greedy decoding. Confidence correlates with reasoning presence.',
      keyEvidence: [
        'Top-k alternatives reveal CoT',
        '10-20%+ improvement over greedy',
        'Higher confidence = CoT path',
      ],
    },
    {
      id: '2508.01191',
      title: 'Is Chain-of-Thought Reasoning a Mirage?',
      shortTitle: 'CoT Mirage',
      date: 'Aug 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        "CoT reasoning is 'brittle mirage' beyond training distribution. ID=100%, OOD=0%. Three failure dimensions: task, length, format.",
      keyEvidence: [
        'ID: 100%, OOD: 0%',
        'Correct reasoning + wrong answer',
        'Small SFT fixes it (data coverage)',
      ],
    },
    {
      id: '2505.05410',
      title: "Reasoning Models Don't Always Say What They Think",
      shortTitle: "Don't Say What They Think",
      date: 'May 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'CoT faithfulness is low even in reasoning models (25-39%). Models hide problematic reasoning MORE. RL plateaus without saturation.',
      keyEvidence: [
        'Claude 3.7: ~25% faithful',
        'Misaligned hints: 20-29% verbalized',
        'Reward hacks: >99% use, <2% verbalized',
      ],
    },
    {
      id: '2507.17699',
      title: "Thinking Isn't an Illusion: Tool Augmentations",
      shortTitle: "Thinking Isn't Illusion",
      date: 'Jul 2025',
      stance: 'challenges',
      cluster: 'tools',
      coreArgument:
        'Tool augmentation reverses collapse. Failure is execution limit, not reasoning limit. LRMs outperform LLMs with tool access.',
      keyEvidence: [
        'Hanoi: 0%→100% with PoT',
        'River Crossing: 80% with tools',
        'Checker Jumping still fails',
      ],
    },
    {
      id: '2506.18957',
      title: 'Comment: Reframing as Agentic Gap',
      shortTitle: 'Agentic Gap',
      date: 'Jun 2025',
      stance: 'challenges',
      cluster: 'tools',
      coreArgument:
        "Models fail at execution within restrictive interface, not reasoning. With agentic tools, models solve problems 'far beyond the reasoning cliff.'",
      keyEvidence: [
        'Execution vs reasoning distinction',
        'Tool use reverses collapse',
        'Missing cognitive baselines',
      ],
    },
    {
      id: '2511.21591',
      title: 'On the Limits of Innate Planning',
      shortTitle: 'Limits of Planning',
      date: 'Nov 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        'External move validator = 0% success. Even with execution offloaded, models fail. Planning is the bottleneck, not execution.',
      keyEvidence: [
        '0% success with move validator',
        'GPT-5-Thinking loops 100%',
        'Refutes Agentic Gap argument',
      ],
    },
    {
      id: '2507.01231',
      title: 'Rethinking the Illusion of Thinking',
      shortTitle: 'Rethinking Illusion',
      date: 'Jul 2025',
      stance: 'balanced',
      cluster: 'complexity',
      coreArgument:
        "River Crossing tested unsolvable configs; Hanoi ~8 disk limit is real. Agentic dialogue makes Hanoi WORSE. LRMs are 'stochastic searchers.'",
      keyEvidence: [
        '~8 disk limit CONFIRMED',
        "Stepwise prompting doesn't fix Hanoi",
        'LRMs solve 200-step solvable problems',
      ],
    },
    {
      id: '2509.17380',
      title: 'Correlation or Causation in CoT Reasoning',
      shortTitle: 'Correlation or Causation',
      date: 'Sep 2025',
      stance: 'balanced',
      cluster: 'faithfulness',
      coreArgument:
        "Only 30% of LLM causal chains are ideal. 47% show CoT doesn't affect answers. RLVR improves to 63% but not 100%.",
      keyEvidence: [
        '30% ideal SCM Type I',
        "47% CoT doesn't affect answers",
        "Distillation doesn't improve causality",
      ],
    },
    {
      id: '2412.13013',
      title: 'Emergence of Strategic Reasoning in LRMs',
      shortTitle: 'Strategic Reasoning',
      date: 'Dec 2024',
      stance: 'challenges',
      cluster: 'emergence',
      coreArgument:
        "GPT-o1 achieves τ=4.42 (4+ reasoning steps), exceeding human strategic reasoning (τ≈1). 'Most fundamental transition' documented.",
      keyEvidence: [
        'τ=4.42 for GPT-o1',
        'Exceeds human (τ≈1)',
        'Performance drops for p=4/3 (OOD)',
      ],
    },
    {
      id: '2503.08679',
      title: 'CoT In The Wild Is Not Always Faithful',
      shortTitle: 'CoT In The Wild',
      date: 'Mar 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        "Unfaithfulness occurs on natural, unbiased prompts. Models answer YES to both 'Is X>Y?' AND 'Is Y>X?' with coherent arguments.",
      keyEvidence: [
        'GPT-4o-mini: 13% unfaithful',
        'Sonnet 3.7 (thinking): 0.04%',
        'Logically contradictory answers',
      ],
    },
    {
      id: '2510.22371',
      title: "Reasoning Models Reason Well, Until They Don't",
      shortTitle: "Until They Don't",
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'complexity',
      coreArgument:
        'Abrupt collapse at L~64-300. NLGraph is trivially easy (L<2). Even o3 fails at L=800. Token usage DECREASES at high complexity.',
      keyEvidence: [
        '99% on NLGraph (trivially easy)',
        '~0% at L=800',
        'Chain graphs fail at depth 1536',
      ],
    },
    {
      id: '2509.12645',
      title: 'LLMs Imitate Logical Reasoning',
      shortTitle: 'Imitate Reasoning',
      date: 'Sep 2025',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'LLMs imitate reasoning via pattern matching. Neuro-symbolic approaches are 7-10x cheaper at higher accuracy.',
      keyEvidence: [
        '2023→2024 = hidden CoT',
        'Pattern matching mechanism',
        'Neuro-symbolic outperforms',
      ],
    },
    {
      id: '2507.10624',
      title: 'Comprehension Without Competence',
      shortTitle: 'Comprehension Without Competence',
      date: 'Jul 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        "'Split-brain': 95-100% step accuracy, 0% final accuracy at 10-digit multiplication. Scale won't help — architectural limit.",
      keyEvidence: [
        '95-100% step accuracy',
        '0% final at 10-digit',
        'Error accumulation proves limit',
      ],
    },
    {
      id: '2509.09677',
      title: 'The Illusion of Diminishing Returns',
      shortTitle: 'Diminishing Returns',
      date: 'Sep 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Self-conditioning: errors beget more errors. Opposite to humans. Thinking models fix this effect.',
      keyEvidence: [
        '0% errors: ~90% accuracy',
        '100% errors: ~40% accuracy',
        'Thinking models: 97% even with errors',
      ],
    },
    {
      id: '2406.15992',
      title: 'Can LLM Graph Reasoning Generalize?',
      shortTitle: 'Graph Reasoning',
      date: 'Jun 2024',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        "'Pattern regurgitators' — EMNLP 2024. 0% strong recovery on reasoning patterns. 100% knowledge doesn't transfer.",
      keyEvidence: ['0% strong recovery', 'Pattern regurgitators', 'EMNLP 2024 Best Paper'],
    },
    {
      id: '2601.13392',
      title: 'Beyond Memorization: ToC Tasks',
      shortTitle: 'Beyond Memorization',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        '100% factual knowledge, 30-64% drop on unseen DFA construction. Perfect knowledge ≠ compositional reasoning.',
      keyEvidence: ['100% factual accuracy', '84-90% seen, 20-59% unseen', 'CoT/ToT only +1-4%'],
    },
    {
      id: '2601.03630',
      title: 'Reasoning Model Is Superior Judge',
      shortTitle: 'Superior Judge',
      date: 'Jan 2026',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        'LRMs better at judgment accuracy but MORE susceptible to superficial biases (32pp drop on BiasBench).',
      keyEvidence: [
        'Better judgment accuracy',
        '32pp drop on BiasBench',
        'Pattern matching metrics',
      ],
    },
    {
      id: '2506.17219',
      title: 'No Free Lunch: Internal Feedback for RL',
      shortTitle: 'No Free Lunch',
      date: 'Jun 2025',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'RLIF degrades reasoning (291→235 correct). Format improves, reasoning degrades. Transitional words suppressed 37%.',
      keyEvidence: [
        '291→235 correct answers',
        'Entropy minimization → shallow reasoning',
        "'but', 'wait' decrease 37%",
      ],
    },
    {
      id: '2508.13678',
      title: 'Neuro-Symbolic AI for Reasoning Survey',
      shortTitle: 'Neuro-Symbolic Survey',
      date: 'Aug 2025',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        "'LLMs cannot really reason... statistical pattern recognition.' Survey of 52 papers. Neuro-symbolic compensates for weaknesses.",
      keyEvidence: [
        '52 papers reviewed',
        'Pattern recognition, not reasoning',
        'Symbolic = System 2',
      ],
    },
    {
      id: '2601.02996',
      title: 'Multilingual Latent Reasoners',
      shortTitle: 'Multilingual Reasoners',
      date: 'Jan 2026',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "Latent reasoning EXISTS but 'real and fragile'. LRS collapses 0.38→0.03 on hard problems. English-centric pathway.",
      keyEvidence: [
        'LRS: 0.38→0.03 (92% drop)',
        'English-centric internal reasoning',
        'Fragile capability',
      ],
    },
    {
      id: '2512.20812',
      title: 'Semantic Deception in LLM Reasoning',
      shortTitle: 'Semantic Deception',
      date: 'Dec 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'Semantic cues override explicit instructions. Reasoning models fail MORE (6-10% at Level 4b). CoT can AMPLIFY biases.',
      keyEvidence: [
        'Reasoning models fail MORE',
        '96% Level 1 → 40% Level 4b',
        'CoT amplifies semantic associations',
      ],
    },
    {
      id: '2510.15974',
      title: 'Limits of Emergent Reasoning in Agentic Settings',
      shortTitle: 'Limits Agentic',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'tools',
      coreArgument:
        "Agentic framework makes collapse WORSE, not better. ~40% deterministic looping. Environment access doesn't help reasoning.",
      keyEvidence: ['Collapse EARLIER with tools', '~40% looping', 'JSD diverges from optimal'],
    },
    {
      id: '2504.01445',
      title: 'Compositional-ARC: Systematicity in Spatial Reasoning',
      shortTitle: 'Compositional-ARC',
      date: 'Apr 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'o3-mini 0.53% on systematicity despite 64% on 3-shot. 5.7M MLC model beats 8B+ LLMs. Memorization, not reasoning.',
      keyEvidence: [
        'o3-mini: 64% 3-shot, 0.53% systematicity',
        '5.7M > 8B+ on composition',
        'MLC: Meta-Learning for Compositionality',
      ],
    },
    {
      id: '2504.12523',
      title: 'KUP: Memorization vs Reasoning',
      shortTitle: 'KUP',
      date: 'Apr 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'ALL methods <2% on reasoning probes. Direct probing (memorization) 70-80%. Retrieval ≠ application.',
      keyEvidence: ['<2% on indirect probing', '70-80% on direct probing', 'H&M Russia example'],
    },
    {
      id: '2509.03646',
      title: 'Emergent Hierarchical Reasoning',
      shortTitle: 'Hierarchical Reasoning',
      date: 'Sep 2025',
      stance: 'challenges',
      cluster: 'emergence',
      coreArgument:
        "RL 'rediscovers' pre-training priors. Improves ID performance via strategic template deployment.",
      keyEvidence: [
        'RL rediscovers priors',
        'Template deployment improves',
        'Challenged by OMEGA (0% transformative)',
      ],
    },
    {
      id: '2510.15987',
      title: 'Algorithmic Primitives in Compositional Geometry',
      shortTitle: 'Algorithmic Primitives',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "Finetuning changes pattern deployment, not capability. Identifiable 'primitives' are learned patterns.",
      keyEvidence: [
        'Patterns identifiable',
        "Deployment changes, capability doesn't",
        'Challenged by Planning Gap',
      ],
    },
    {
      id: '2502.20332',
      title: 'Emergent Symbolic Mechanisms in LLMs',
      shortTitle: 'Symbolic Mechanisms',
      date: 'Feb 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Three-stage architecture: positional→value→abstraction. 98% cross-token generalization. Abstraction is positional, not semantic.',
      keyEvidence: [
        'Three-stage architecture',
        '98% cross-token generalization',
        'Positional abstraction',
      ],
    },
    {
      id: '2509.23629',
      title: 'How LLMs Learn to Reason: A Complex Network Perspective',
      shortTitle: 'Complex Network',
      date: 'Sep 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "RL 'weaves' existing skill islands via concept web. Policy collapse mechanism. Sparse web has limited paths.",
      keyEvidence: [
        'Concept web structure',
        'Policy collapse dynamics',
        'Sparse tree limits paths',
      ],
    },
    {
      id: '2601.08058',
      title: 'Reasoning Beyond CoT: Latent Mode Steering',
      shortTitle: 'Beyond CoT',
      date: 'Jan 2026',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Reasoning can be elicited without explicit CoT. SAE features steer latent mode. Internal mechanisms identifiable.',
      keyEvidence: ['Latent mode steering', 'SAE feature steering', 'No OOD testing done'],
    },
    {
      id: '2512.04727',
      title: 'Sequential Enumeration in LLMs',
      shortTitle: 'Sequential Enumeration',
      date: 'Dec 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        'Counting uses token patterns, not true algorithms. No spontaneous counting. Works only when trained patterns apply.',
      keyEvidence: ['Pattern-based counting', 'No spontaneous counting', 'Fails OOD'],
    },
    {
      id: '2512.13713',
      title: 'LoopBench: Meta-Cognitive Symmetry Breaking',
      shortTitle: 'LoopBench',
      date: 'Dec 2025',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        "Only O3 develops 'wait' strategies to escape deadlocks (72%). GPT-4.1: 0%. Discovery-Implementation Gap.",
      keyEvidence: [
        'O3: 72%, GPT-4.1: 0%',
        'Meta-cognitive strategies rare',
        'Discovery-Implementation Gap',
      ],
    },
    {
      id: '2509.13334',
      title: 'FRIT: Faithfulness via Causal Intervention',
      shortTitle: 'FRIT',
      date: 'Sep 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        '25-60% unfaithfulness rates. Automated intervention improves faithfulness. Accuracy emerges from faithfulness training.',
      keyEvidence: ['25-60% unfaithful', 'Automated intervention works', 'Faithfulness → accuracy'],
    },
    {
      id: '2510.22362',
      title: 'Mapping Faithful Reasoning Paths',
      shortTitle: 'Faithful Paths',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'faithfulness',
      coreArgument:
        "Mechanistic evidence for unfaithfulness. 'Concept Walk' distinguishes computational vs decorative reasoning.",
      keyEvidence: ['Easy/hard case distinction', 'Concept Walk method', 'CoT can be decorative'],
    },
    {
      id: '2502.14829',
      title: 'CoT Faithfulness via Unlearning',
      shortTitle: 'Faithfulness Unlearning',
      date: 'Feb 2025',
      stance: 'balanced',
      cluster: 'faithfulness',
      coreArgument:
        'Parametric intervention improves faithfulness. Faithfulness ≠ plausibility. Contextual methods underestimate.',
      keyEvidence: [
        'Parametric vs contextual',
        'Challenges add-mistake baseline',
        'Faithfulness ≠ plausibility',
      ],
    },
    {
      id: '2601.02989',
      title: 'Mechanistic Analysis of Counting in LLMs',
      shortTitle: 'Mechanistic Counting',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        '0% accuracy at 41-50 items. Error accumulation with sequential steps. Needs structural decomposition, not just more tokens.',
      keyEvidence: ['0% at 41-50 items', 'Depth-bounded', 'Structural decomposition needed'],
    },
    {
      id: '2509.18458',
      title: 'CogniLoad: Cognitive Load Benchmark',
      shortTitle: 'CogniLoad',
      date: 'Sep 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        'State-tracking errors dominate at complexity. System-1 reasoning fails at scale. Links CLT to LLM evaluation.',
      keyEvidence: [
        'State-tracking errors',
        'System-1 fails at scale',
        'Cognitive load theory applied',
      ],
    },
    {
      id: '2601.13244',
      title: 'Instruction-Tuned Models Not Always Better',
      shortTitle: 'Instruction Not Better',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'Capabilities exist in base model; training surfaces them. SFT/RL can degrade reasoning while improving format.',
      keyEvidence: [
        'Base models often win',
        'Perturbation brittleness',
        'Surfacing hypothesis support',
      ],
    },
    {
      id: '2407.20311',
      title: 'Physics of LLMs 2.1: Grade School Math',
      shortTitle: 'Physics of LLMs',
      date: 'Jul 2024',
      stance: 'challenges',
      cluster: 'emergence',
      coreArgument:
        'Shows genuine OOD generalization, not just template matching. Length generalization achievable with iGSM.',
      keyEvidence: [
        'OOD generalization shown',
        'iGSM controlled study',
        'Challenges thesis (narrow domain)',
      ],
    },
    {
      id: '2504.20771',
      title: 'TMBench: Turing Machine Simulation Benchmark',
      shortTitle: 'TMBench',
      date: 'Apr 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        "Performance collapse at scale. Error accumulation with sequential steps. 'Inevitable failure due to statistical nature.'",
      keyEvidence: ['Collapse at scale', 'Error accumulation', 'Statistical nature limits'],
    },
    {
      id: '2510.04040',
      title: 'FaithCoT-Bench: Instance-Level Faithfulness Detection',
      shortTitle: 'FaithCoT-Bench',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        '40-60% unfaithfulness rates. OOD unfaithfulness: 20%→74%. 1,000+ annotated trajectories.',
      keyEvidence: ['40-60% unfaithful', '20%→74% OOD unfaithfulness', '1,000+ annotations'],
    },
    {
      id: '2601.10825',
      title: 'Societies of Thought in Reasoning Models',
      shortTitle: 'Societies of Thought',
      date: 'Jan 2026',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'R1 achieves performance via multi-agent dialogue simulation. RL organizes pre-existing conversational patterns.',
      keyEvidence: ['Multi-agent simulation', 'RL organizes patterns', 'No OOD testing'],
    },
    {
      id: '2511.23476',
      title: 'Thinking by Doing: WMACT Framework',
      shortTitle: 'Thinking by Doing',
      date: 'Nov 2025',
      stance: 'balanced',
      cluster: 'tools',
      coreArgument:
        'RL requires pre-existing capability. Monolithic reasoning can HARM performance. Authors state prerequisites.',
      keyEvidence: [
        'Pre-existing capability needed',
        'Monolithic can harm',
        'No truly OOD testing',
      ],
    },
    {
      id: '2505.23945',
      title: 'Bias and CoT Faithfulness in VLMs',
      shortTitle: 'Bias VLM Faithfulness',
      date: 'May 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'SFT training shows NO improvement. Visual biases systematically less articulated. RL helps only for explicit biases.',
      keyEvidence: ['SFT no improvement', 'Visual biases hidden', 'RL limited help'],
    },
    {
      id: '2501.02497',
      title: 'Survey of Test-Time Compute Methods',
      shortTitle: 'Test-Time Survey',
      date: 'Jan 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Self-correction limited without external feedback. Sequential scaling fails; parallel scaling works better.',
      keyEvidence: ['Self-correction limited', 'Sequential fails', 'Parallel scaling better'],
    },
    {
      id: '2404.00560',
      title: 'A Theory for Length Generalization',
      shortTitle: 'Length Gen Theory',
      date: 'Apr 2024',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'LG requires D=X (training covers all inputs). Standard formulations fail. Explains why surface perturbations break models.',
      keyEvidence: ['D=X required', 'Standard formulations fail', 'Complete coverage needed'],
    },
    {
      id: '2510.08931',
      title: 'RADAR: Data Contamination Detection',
      shortTitle: 'RADAR',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'Mechanistic detection of memorization. Early convergence = pattern matching. Distributed attention = reasoning.',
      keyEvidence: [
        'Memorization detection',
        'Early convergence pattern',
        'Attention distribution analysis',
      ],
    },
    {
      id: '2504.05262',
      title: 'Do LLMs Truly Grasp Elementary Addition?',
      shortTitle: 'Grasp Addition',
      date: 'Apr 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        '99.8%→7.5% with symbolic representation. Commutativity violations prove no abstract rule learning. SFT surfaces patterns (97.17%), no transfer (0%).',
      keyEvidence: ['99.8%→7.5% symbolic', 'Commutativity violations', '0% symbolic transfer'],
    },
    {
      id: '2512.13978',
      title: 'PhD-Level Mathematical Reasoning Benchmark',
      shortTitle: 'PhD Math',
      date: 'Dec 2025',
      stance: 'balanced',
      cluster: 'complexity',
      coreArgument:
        '~34% failure rate on structured reasoning. 66% success suggests meaningful capability exists in narrow domains.',
      keyEvidence: ['~34% failure rate', '66% success (R1)', 'Novel compositions fail'],
    },
    {
      id: '2410.13343',
      title: 'Shortcut Learning in Mathematical Reasoning',
      shortTitle: 'Shortcut Learning',
      date: 'Oct 2024',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'High accuracy hides brittleness to perturbations. Pattern matching over genuine reasoning.',
      keyEvidence: [
        'Brittleness to perturbations',
        'Pattern matching mechanism',
        'Structural changes break models',
      ],
    },
    {
      id: '2409.02257',
      title: 'MMLU-Pro+: Shortcut Detection Benchmark',
      shortTitle: 'MMLU-Pro+',
      date: 'Sep 2024',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'LLMs exploit shortcuts. SSR and CPI metrics for anchoring bias detection. Format changes expose brittleness.',
      keyEvidence: ['Shortcut exploitation', 'SSR/CPI metrics', 'Format brittleness'],
    },
    {
      id: '2601.03676',
      title: 'STEPS: Skill Taxonomy for Compositional Learning',
      shortTitle: 'STEPS',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'Power-law distribution explains compositional scarcity. 4K targeted > 52K random. Data bottleneck for k>1 compositions.',
      keyEvidence: ['Power-law distribution', '4K > 52K', 'Data bottleneck k>1'],
    },
    {
      id: '2509.01267',
      title: 'Iterative ICL for Algebraic Tasks',
      shortTitle: 'Iterative ICL',
      date: 'Sep 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        '13-35% on rule override. Simpler examples work better. Learned priors dominate over instructions.',
      keyEvidence: ['13-35% rule override', 'Simpler examples better', 'Priors dominate'],
    },
    {
      id: '2506.15629',
      title: 'Revisiting Compositional Generalization (ACL 2025)',
      shortTitle: 'Revisiting Compositional',
      date: 'Jun 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        '75% ceiling on ordered coverage. Models default to preferred orderings. Instructions cannot override learned patterns.',
      keyEvidence: ['75% ceiling', 'Preferred orderings', 'ACL 2025'],
    },
    {
      id: '2504.09858',
      title: 'Effective Reasoning Without Extended Thinking',
      shortTitle: 'Effective Without Thinking',
      date: 'Apr 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Extended thinking not necessary for correctness. If thinking skippable, tokens not causal for correctness.',
      keyEvidence: ['Thinking skippable', 'Questions R1 value', 'Supports latent reasoning'],
    },
    {
      id: '2506.21215',
      title: 'Unveiling Causal Reasoning in LLMs',
      shortTitle: 'Unveiling Causal',
      date: 'Jun 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'Level-1 (retrieval) vs Level-2 (genuine reasoning) distinction. Fresh data reveals memorization. Pattern matching thesis supported.',
      keyEvidence: ['L1 vs L2 distinction', 'Fresh data test', 'Memorization revealed'],
    },
    {
      id: '2503.05788',
      title: 'Emergent Abilities Survey',
      shortTitle: 'Emergence Survey',
      date: 'Mar 2025',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        'Metric choice affects emergence detection. Some emergence is real (modular arithmetic). Challenges both Wei and Schaeffer.',
      keyEvidence: [
        'Metric affects detection',
        'Some emergence real',
        'Challenges original claims',
      ],
    },
    {
      id: '2510.20783',
      title: 'Chess Transformers: Compositionality Study',
      shortTitle: 'Chess Compositionality',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'compositional',
      coreArgument:
        'Rules generalize (96%+), but strategies fail (70%→22%). Rule following ≠ reasoning. Strategies distribution-bounded.',
      keyEvidence: ['Rules: 96%+ OOD', 'Strategies: 70%→22%', 'Rule ≠ reasoning'],
    },
    {
      id: '2505.16782',
      title: 'Survey of Latent CoT Reasoning',
      shortTitle: 'Latent CoT Survey',
      date: 'May 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "'Unclear whether genuine reasoning or exploiting correlations.' Clear taxonomy of approaches.",
      keyEvidence: [
        'Unclear genuine vs correlation',
        'Taxonomy provided',
        'Both views have evidence',
      ],
    },
    {
      id: '2502.07813',
      title: 'CryptoX: Compositional Reasoning with Encoding',
      shortTitle: 'CryptoX',
      date: 'Feb 2025',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        '40-54pp drops with encoding. Hierarchical layer processing. Open/closed gap reveals training data dependence.',
      keyEvidence: ['40-54pp encoding drops', 'Hierarchical processing', 'AUC 2.47 vs 4.05'],
    },
    {
      id: '2510.27378',
      title: 'Measuring CoT Monitorability',
      shortTitle: 'CoT Monitorability',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'Verbosity ≠ faithfulness. Models leave out key factors even when faithful. Monitorability framework.',
      keyEvidence: ['Verbosity ≠ faithfulness', 'Key factors omitted', 'Monitorability framework'],
    },
    {
      id: '2403.11793',
      title: 'Reasoning Abilities on ARC/LoTH',
      shortTitle: 'ARC/LoTH',
      date: 'Mar 2024',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        "10.6% correct answers but only 4.0% correct processes. 60% 'lucky' correct. 0% on Medium/Hard ARC.",
      keyEvidence: ['10.6%→4.0% process correct', '60% lucky', '0% Medium/Hard'],
    },
    {
      id: '2504.00294',
      title: 'Inference-Time Scaling on Complex Tasks',
      shortTitle: 'Inference Scaling',
      date: 'Apr 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'GPT-4o approaches O1 with 256× superscaling. Complexity collapse persists. Task-dependent effectiveness.',
      keyEvidence: ['256× superscaling helps', 'Collapse persists', 'Task-dependent'],
    },
    {
      id: '2510.09312',
      title: 'CRV: Verifying CoT via Computational Graphs',
      shortTitle: 'CRV',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'faithfulness',
      coreArgument:
        'Error signatures domain-specific (92%→55% cross-domain). Causal interventions work. Mechanistic verification.',
      keyEvidence: ['92%→55% cross-domain', 'Causal interventions', 'Domain-specific signatures'],
    },
    {
      id: '2502.12215',
      title: 'Revisiting Test-Time Scaling',
      shortTitle: 'Revisiting TTS',
      date: 'Feb 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Sequential scaling fails. Parallel scaling works better. External feedback needed.',
      keyEvidence: ['Sequential fails', 'Parallel better', 'External feedback needed'],
    },
    {
      id: '2510.22437',
      title: 'Hierarchical Thinking FSM Analysis',
      shortTitle: 'Thinking FSM',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        "Extended thinking doesn't always help (GPQA: longer = worse). FSM framework for tracking state transitions.",
      keyEvidence: ['GPQA: longer = worse', 'FSM framework', 'Task-dependent benefit'],
    },
    {
      id: '2510.25013',
      title: 'IOI Minimal Circuits Analysis',
      shortTitle: 'IOI Circuits',
      date: 'Oct 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Task-constrained training finds simpler circuits than GPT-2. Identifiable reasoning circuits exist.',
      keyEvidence: ['Simpler circuits found', 'Task-constrained training', 'Challenges GPT-2 IOI'],
    },
    {
      id: '2512.23722',
      title: 'Emergent World Beliefs in POMDP',
      shortTitle: 'World Beliefs',
      date: 'Dec 2025',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        'Extends Othello/Chess world model paradigm to POMDP. Evidence for internal representations. Probed features may not be causally used.',
      keyEvidence: ['POMDP extension', 'Internal representations', 'Causal use unclear'],
    },
    {
      id: '2601.16823',
      title: 'Trapped in the past? Disentangling fluid and crystallized intelligence using chess',
      shortTitle: 'Trapped in the Past',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'OOD chess performance collapses to random despite strong in-distribution play. Crystallized (memorization) dominates over fluid (reasoning) intelligence.',
      keyEvidence: [
        'WD: good, OOD: random',
        'Reasoning tokens diminishing returns OOD',
        'Crystallized > fluid intelligence',
      ],
    },
    {
      id: '2601.16853',
      title: 'Reasoning Promotes Robustness in Theory of Mind Tasks',
      shortTitle: 'ToM Robustness',
      date: 'Jan 2026',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        'Reasoning models show improved robustness on ToM tasks, but this is NOT new capability—bounded by base model capability. Supports "surfacing" hypothesis.',
      keyEvidence: [
        'Robustness ≠ new capability',
        'Bounded by base model',
        'ToM strategies visible in traces',
      ],
    },
    {
      id: '2601.18790',
      title: 'MortalMATH: Reasoning Objectives vs Emergency Contexts',
      shortTitle: 'MortalMATH',
      date: 'Jan 2026',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'Reasoning models maintain >95% task completion while user describes dying. RLVR creates "tunnel vision" — optimized pattern pursuit blinds models to context.',
      keyEvidence: [
        '>95% task completion during emergencies',
        'RLVR creates tunnel vision',
        '15s latency in emergencies',
      ],
    },
    {
      id: '2406.10625',
      title: 'On the Hardness of Faithful Chain-of-Thought Reasoning',
      shortTitle: 'Hardness of Faithfulness',
      date: 'Jun 2024',
      stance: 'supports',
      cluster: 'faithfulness',
      coreArgument:
        'Faithfulness-accuracy tradeoff is fundamental. All interventions fail. Larger models are LESS faithful. GPT-4 gets correct answers WITHOUT using CoT.',
      keyEvidence: [
        'All intervention classes fail',
        'Larger models less faithful',
        'GPT-4 correct without CoT',
      ],
    },
    {
      id: '2507.18391',
      title: 'Revisiting LLM Reasoning via Information Bottleneck',
      shortTitle: 'IB Reasoning',
      date: 'Jul 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'IB regularization improves RL by ~2 points. Reconciles entropy debate. Token-level advantage x entropy.',
      keyEvidence: [
        '~2 point average gain',
        'One-line code change',
        'Reconciles entropy debate',
      ],
    },
    {
      id: '2509.26306',
      title: 'Interactive Learning for LLM Reasoning (ILR)',
      shortTitle: 'Interactive Learning',
      date: 'Sep 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Multi-agent co-learning improves individual reasoning by 3-5%. Dynamic cooperation/competition. No OOD testing.',
      keyEvidence: [
        '3-5% improvement',
        'Dynamic interaction',
        'No OOD testing',
      ],
    },
    {
      id: '2510.10182',
      title: 'A Survey of Inductive Reasoning for LLMs',
      shortTitle: 'Inductive Survey',
      date: 'Oct 2025',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'Inductive ability originates from induction heads = pattern matching. No universal bias. Test-time scaling = search through learned patterns.',
      keyEvidence: [
        'Induction heads = pattern matching',
        'No universal bias',
        'Simplicity preference',
      ],
    },
    {
      id: '2512.01222',
      title: 'Unsupervised Decoding of Encoded Reasoning',
      shortTitle: 'Decoding Reasoning',
      date: 'Dec 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'Logit lens decodes ROT-13 ~75%. Internal representations anchor to English. Interpretability can penetrate encoding.',
      keyEvidence: [
        '~75% decoding accuracy',
        'English-anchored internals',
        'Layers 54-62 peak',
      ],
    },
    {
      id: '2601.14716',
      title: 'PCL-Reasoner-V1.5: Offline RL for Math Reasoning',
      shortTitle: 'PCL-Reasoner',
      date: 'Jan 2026',
      stance: 'challenges',
      cluster: 'emergence',
      coreArgument:
        'Offline RL achieves 90.9% AIME 2024. RL improves long-CoT specifically. Depends on DeepSeek-R1 distillation.',
      keyEvidence: [
        '90.9% AIME 2024',
        '85.6% AIME 2025',
        'Offline RL stable',
      ],
    },
    {
      id: '2502.15631',
      title: 'o3 (mini) Thinks Harder, Not Longer',
      shortTitle: 'o3 Thinks Harder',
      date: 'Feb 2025',
      stance: 'supports',
      cluster: 'complexity',
      coreArgument:
        'Accuracy DECLINES as reasoning chains grow. More capable models use tokens more effectively, not more of them. Overthinking mechanism quantified.',
      keyEvidence: [
        '3.16%/1000 tokens accuracy drop (o1-mini)',
        'o3-mini: same tokens, higher accuracy',
        'Error accumulation with chain length',
      ],
    },
    {
      id: '2502.12470',
      title: 'Reasoning on a Spectrum: System 1 and System 2 Alignment',
      shortTitle: 'S1/S2 Alignment',
      date: 'Feb 2025',
      stance: 'balanced',
      cluster: 'mechanism',
      coreArgument:
        'System 2 excels at arithmetic/symbolic; System 1 excels at commonsense. Uniform reasoning suboptimal. Entropy-based selection beats both pure approaches.',
      keyEvidence: [
        'S2: +9pp AddSub, +17pp SingleEq',
        'S1: +7pp StrategyQA, +4pp SIQA',
        'Entropy selection = best of both',
      ],
    },
    {
      id: '2207.07051',
      title: 'Language Models Show Human-like Content Effects on Reasoning',
      shortTitle: 'Content Effects',
      date: 'Jul 2024',
      stance: 'supports',
      cluster: 'compositional',
      coreArgument:
        'LLMs and humans both show content effects: reasoning more accurate when semantic content supports logical inference. Both rely on learned patterns, not pure logic.',
      keyEvidence: [
        '90% endorse invalid syllogism if believable',
        'Model confidence ↔ human RT correlation',
        'PNAS Nexus peer-reviewed',
      ],
    },
    {
      id: '2411.02478',
      title: 'Imagining and Building Wise Machines: The Centrality of AI Metacognition',
      shortTitle: 'AI Metacognition',
      date: 'Nov 2024',
      stance: 'supports',
      cluster: 'mechanism',
      coreArgument:
        'AI has become smart but not wise. Lacks metacognition (reasoning about reasoning). Object-level patterns without meta-level strategy selection.',
      keyEvidence: [
        'Bengio, Mitchell, Chater et al.',
        'Wisdom = knowing WHEN patterns apply',
        'Missing: self-monitoring, error detection',
      ],
    },
    {
      id: '2507.15851',
      title: 'The Other Mind: How Language Models Exhibit Human Temporal Cognition',
      shortTitle: 'Temporal Cognition',
      date: 'Jul 2025',
      stance: 'balanced',
      cluster: 'emergence',
      coreArgument:
        'LLMs exhibit Weber-Fechner law with reference point ~2025. Sophisticated emergence FROM training data structure, not despite it.',
      keyEvidence: [
        'Reference point ~2025 (GPT-4o: 2024)',
        '0.67-1.71% temporal-preferential neurons',
        'Emerges from corpus structure',
      ],
    },
  ],
  links: [
    {
      source: '2506.18880',
      target: '2305.18654',
      type: 'supports',
      description: 'Compositional generalization failure',
    },
    {
      source: '2506.18880',
      target: '2601.14456',
      type: 'supports',
      description: 'ID/OOD gap pattern',
    },
    {
      source: '2506.18880',
      target: '2512.07783',
      type: 'supports',
      description: "RL surfaces, doesn't create",
    },
    {
      source: '2506.18880',
      target: '2506.06941',
      type: 'supports',
      description: 'Performance collapse at threshold',
    },
    {
      source: '2506.18880',
      target: '2410.05229',
      type: 'extends',
      description: 'From perturbation to generalization axes',
    },
    {
      source: '2512.07783',
      target: '2501.19393',
      type: 'supports',
      description: 'Controlled evidence for surfacing',
    },
    {
      source: '2512.07783',
      target: '2501.12948',
      type: 'supports',
      description: "RL surfaces, doesn't create",
    },
    {
      source: '2510.22371',
      target: '2506.06941',
      type: 'supports',
      description: 'Abrupt collapse pattern',
    },
    {
      source: '2510.22371',
      target: '2305.18654',
      type: 'supports',
      description: 'Propagation error mechanism',
    },
    {
      source: '2508.01191',
      target: '2305.18654',
      type: 'supports',
      description: 'ID=100%, OOD=0%',
    },
    {
      source: '2410.05229',
      target: '2305.18654',
      type: 'supports',
      description: 'Distribution-dependent failure',
    },
    {
      source: '2601.00514',
      target: '2501.12948',
      type: 'rebuts',
      description: "Aha moments are rare, don't help",
    },
    {
      source: '2601.00514',
      target: '2307.13702',
      type: 'supports',
      description: 'Shifts are unfaithful',
    },
    {
      source: '2601.00514',
      target: '2505.05410',
      type: 'supports',
      description: "CoT doesn't reflect computation",
    },
    {
      source: '2509.12645',
      target: '2305.18654',
      type: 'supports',
      description: 'Imitation = pattern matching',
    },
    {
      source: '2509.12645',
      target: '2506.06941',
      type: 'supports',
      description: 'Not genuine reasoning',
    },
    {
      source: '2507.07313',
      target: '2506.06941',
      type: 'supports',
      description: 'Same abrupt collapse',
    },
    {
      source: '2507.07313',
      target: '2305.18654',
      type: 'supports',
      description: 'Error accumulation mechanism',
    },
    {
      source: '2507.07313',
      target: '2410.05229',
      type: 'supports',
      description: 'Distribution-dependent failures',
    },
    {
      source: '2507.07313',
      target: '2501.12948',
      type: 'challenges',
      description: 'R1 at 0% character counting',
    },
    {
      source: '2510.18254',
      target: '2601.00514',
      type: 'supports',
      description: 'Reflection = fluent text, not correction',
    },
    {
      source: '2510.18254',
      target: '2307.13702',
      type: 'supports',
      description: 'CoT text ≠ internal computation',
    },
    {
      source: '2510.18254',
      target: '2501.12948',
      type: 'challenges',
      description: 'Reasoning models no better',
    },
    {
      source: '2510.18254',
      target: '2501.19393',
      type: 'challenges',
      description: "Test-time compute doesn't guarantee improvement",
    },
    {
      source: '2506.17219',
      target: '2512.07783',
      type: 'supports',
      description: 'RL requires pre-existing capability',
    },
    {
      source: '2506.17219',
      target: '2601.00514',
      type: 'supports',
      description: "Internal signals don't improve",
    },
    {
      source: '2506.17219',
      target: '2305.18654',
      type: 'supports',
      description: 'Transitional word loss = exploration loss',
    },
    {
      source: '2601.14456',
      target: '2305.18654',
      type: 'supports',
      description: 'ID/OOD gap; surface pattern matching',
    },
    {
      source: '2601.14456',
      target: '2512.07783',
      type: 'supports',
      description: "RL doesn't improve OOD",
    },
    {
      source: '2601.14456',
      target: '2601.13392',
      type: 'supports',
      description: 'Same pattern: high ID, zero OOD',
    },
    {
      source: '2601.14456',
      target: '2410.05229',
      type: 'supports',
      description: 'Surface form sensitivity',
    },
    {
      source: '2601.13392',
      target: '2406.15992',
      type: 'supports',
      description: 'Pattern regurgitators',
    },
    {
      source: '2601.13392',
      target: '2305.18654',
      type: 'supports',
      description: 'Distribution-bounded failures',
    },
    {
      source: '2601.13392',
      target: '2508.01191',
      type: 'supports',
      description: 'ID success, OOD failure',
    },
    {
      source: '2601.13392',
      target: '2410.05229',
      type: 'supports',
      description: 'Brittleness to variations',
    },
    {
      source: '2511.21591',
      target: '2506.18957',
      type: 'rebuts',
      description: "Move validator = 0%; execution isn't bottleneck",
    },
    {
      source: '2511.21591',
      target: '2507.17699',
      type: 'rebuts',
      description: "Tool augmentation doesn't always work",
    },
    {
      source: '2507.17699',
      target: '2506.06941',
      type: 'rebuts',
      description: 'Tool augmentation restores performance',
    },
    {
      source: '2506.18957',
      target: '2506.06941',
      type: 'rebuts',
      description: 'Execution gap, not reasoning gap',
    },
    {
      source: '2503.08679',
      target: '2307.13702',
      type: 'extends',
      description: 'Natural prompts unfaithfulness',
    },
    {
      source: '2505.05410',
      target: '2307.13702',
      type: 'extends',
      description: 'Extends to reasoning models',
    },
    {
      source: '2507.01231',
      target: '2506.06941',
      type: 'supports',
      description: 'Hanoi ~8 disk limit confirmed',
    },
    {
      source: '2507.01231',
      target: '2506.18957',
      type: 'challenges',
      description: 'Agentic dialogue makes Hanoi WORSE',
    },
    {
      source: '2507.01231',
      target: '2507.17699',
      type: 'challenges',
      description: 'Base reasoning genuinely limited',
    },
    {
      source: '2508.13678',
      target: '2305.18654',
      type: 'supports',
      description: 'Errors propagate and amplify',
    },
    {
      source: '2508.13678',
      target: '2509.12645',
      type: 'supports',
      description: 'Replicate reasoning, cannot really reason',
    },
    {
      source: '2601.02996',
      target: '2402.10200',
      type: 'supports',
      description: 'Latent reasoning exists',
    },
    {
      source: '2601.02996',
      target: '2512.07783',
      type: 'supports',
      description: 'English-centric = distribution-bounded',
    },
    {
      source: '2601.02996',
      target: '2506.06941',
      type: 'supports',
      description: 'Collapses on hard problems',
    },
    {
      source: '2509.03646',
      target: '2512.07783',
      type: 'supports',
      description: 'RL rediscovers pre-training priors',
    },
    {
      source: '2509.03646',
      target: '2501.12948',
      type: 'supports',
      description: 'RL improves ID performance',
    },
    {
      source: '2510.15987',
      target: '2509.03646',
      type: 'supports',
      description: 'Finetuning changes deployment, not capability',
    },
    {
      source: '2510.15987',
      target: '2512.07783',
      type: 'supports',
      description: 'Primitives depend on learned patterns',
    },
    {
      source: '2502.20332',
      target: '2510.15987',
      type: 'supports',
      description: 'Identifiable mechanisms',
    },
    {
      source: '2502.20332',
      target: '2402.10200',
      type: 'supports',
      description: 'Latent reasoning capabilities',
    },
    {
      source: '2509.23629',
      target: '2512.07783',
      type: 'supports',
      description: 'RL integrates existing patterns',
    },
    {
      source: '2509.23629',
      target: '2506.17219',
      type: 'supports',
      description: 'Policy collapse mechanism',
    },
    {
      source: '2509.23629',
      target: '2506.06941',
      type: 'supports',
      description: 'Sparse web → collapse',
    },
    {
      source: '2601.08058',
      target: '2402.10200',
      type: 'supports',
      description: 'Reasoning elicitable without CoT',
    },
    {
      source: '2601.08058',
      target: '2502.20332',
      type: 'supports',
      description: 'Specific mechanisms identified',
    },
    {
      source: '2512.04727',
      target: '2305.18654',
      type: 'supports',
      description: 'Counting uses token patterns',
    },
    {
      source: '2512.04727',
      target: '2506.18880',
      type: 'supports',
      description: 'Counting = compositional skill fails OOD',
    },
    {
      source: '2512.04727',
      target: '2506.06941',
      type: 'supports',
      description: 'Systematic failure on counting',
    },
    {
      source: '2504.20771',
      target: '2506.06941',
      type: 'supports',
      description: 'Performance collapse at scale',
    },
    {
      source: '2504.20771',
      target: '2305.18654',
      type: 'supports',
      description: 'Error accumulation',
    },
    {
      source: '2407.20311',
      target: '2305.18654',
      type: 'challenges',
      description: 'Shows genuine OOD generalization',
    },
    {
      source: '2407.20311',
      target: '2512.07783',
      type: 'supports',
      description: 'Capability must exist in training',
    },
    {
      source: '2510.04040',
      target: '2503.08679',
      type: 'supports',
      description: 'Pervasive unfaithfulness',
    },
    {
      source: '2510.04040',
      target: '2307.13702',
      type: 'supports',
      description: 'Confirms unfaithfulness',
    },
    {
      source: '2510.04040',
      target: '2505.05410',
      type: 'supports',
      description: '40-60% unfaithfulness rates',
    },
    {
      source: '2601.10825',
      target: '2501.12948',
      type: 'supports',
      description: 'Explains R1 via multi-agent simulation',
    },
    {
      source: '2601.10825',
      target: '2509.23629',
      type: 'supports',
      description: 'RL organizes conversational patterns',
    },
    {
      source: '2511.23476',
      target: '2512.07783',
      type: 'supports',
      description: 'RL requires pre-existing capability',
    },
    {
      source: '2511.23476',
      target: '2504.09858',
      type: 'supports',
      description: 'Monolithic reasoning can harm',
    },
    { source: '2505.23945', target: '2307.13702', type: 'extends', description: 'Extends to VLMs' },
    {
      source: '2505.23945',
      target: '2505.05410',
      type: 'supports',
      description: 'Visual biases less articulated',
    },
    {
      source: '2510.20783',
      target: '2502.20332',
      type: 'supports',
      description: 'Identifiable mechanisms',
    },
    {
      source: '2510.20783',
      target: '2506.18880',
      type: 'supports',
      description: 'Rules generalize, strategies fail',
    },
    {
      source: '2601.02989',
      target: '2506.06941',
      type: 'supports',
      description: 'Collapse at complexity threshold',
    },
    {
      source: '2601.02989',
      target: '2512.04727',
      type: 'supports',
      description: "Can't count at scale",
    },
    {
      source: '2601.02989',
      target: '2305.18654',
      type: 'supports',
      description: 'Error accumulation, depth-bounded',
    },
    {
      source: '2509.18458',
      target: '2506.06941',
      type: 'supports',
      description: 'State-tracking errors dominate',
    },
    {
      source: '2509.18458',
      target: '2601.02989',
      type: 'supports',
      description: 'System-1 fails at scale',
    },
    {
      source: '2601.13244',
      target: '2512.07783',
      type: 'supports',
      description: 'Capabilities exist in base model',
    },
    {
      source: '2601.13244',
      target: '2506.17219',
      type: 'supports',
      description: 'SFT/RL can degrade reasoning',
    },
    {
      source: '2509.13334',
      target: '2307.13702',
      type: 'extends',
      description: 'Intervention method for faithfulness',
    },
    {
      source: '2509.13334',
      target: '2505.05410',
      type: 'supports',
      description: '25-60% unfaithfulness',
    },
    {
      source: '2510.22362',
      target: '2307.13702',
      type: 'supports',
      description: 'Mechanistic unfaithfulness evidence',
    },
    {
      source: '2510.22362',
      target: '2505.05410',
      type: 'supports',
      description: 'CoT can be decorative',
    },
    {
      source: '2510.25013',
      target: '2502.20332',
      type: 'supports',
      description: 'Identifiable circuits',
    },
    {
      source: '2510.08931',
      target: '2410.05229',
      type: 'supports',
      description: 'Mechanistic memorization detection',
    },
    {
      source: '2510.08931',
      target: '2601.13392',
      type: 'supports',
      description: 'Memorization vs reasoning distinction',
    },
    {
      source: '2510.22437',
      target: '2506.06941',
      type: 'supports',
      description: "Extended thinking doesn't always help",
    },
    {
      source: '2510.22437',
      target: '2504.09858',
      type: 'supports',
      description: 'Sometimes shorter is better',
    },
    {
      source: '2504.05262',
      target: '2410.05229',
      type: 'supports',
      description: 'High accuracy hides brittleness',
    },
    {
      source: '2504.05262',
      target: '2305.18654',
      type: 'supports',
      description: 'Pattern matching, no abstract rules',
    },
    {
      source: '2504.05262',
      target: '2512.04727',
      type: 'supports',
      description: "Can't compute algorithmically",
    },
    {
      source: '2512.13978',
      target: '2601.14456',
      type: 'supports',
      description: 'Failure on structured reasoning',
    },
    {
      source: '2512.13978',
      target: '2506.18880',
      type: 'supports',
      description: 'Struggle with novel compositions',
    },
    {
      source: '2410.13343',
      target: '2410.05229',
      type: 'supports',
      description: 'Brittleness to perturbations',
    },
    {
      source: '2410.13343',
      target: '2305.18654',
      type: 'supports',
      description: 'Pattern matching over reasoning',
    },
    {
      source: '2409.02257',
      target: '2410.13343',
      type: 'supports',
      description: 'Shortcut exploitation',
    },
    {
      source: '2409.02257',
      target: '2410.05229',
      type: 'supports',
      description: 'Format changes expose brittleness',
    },
    {
      source: '2512.01222',
      target: '2601.08058',
      type: 'supports',
      description: 'Internal representations interpretable',
    },
    {
      source: '2512.01222',
      target: '2502.20332',
      type: 'supports',
      description: 'Semantic structure in layers',
    },
    {
      source: '2506.21215',
      target: '2305.18654',
      type: 'supports',
      description: 'Pattern matching over reasoning',
    },
    {
      source: '2506.21215',
      target: '2410.05229',
      type: 'supports',
      description: 'High accuracy hides brittleness',
    },
    {
      source: '2506.21215',
      target: '2601.14456',
      type: 'supports',
      description: 'ID/OOD gap evidence',
    },
    {
      source: '2503.05788',
      target: '2410.05229',
      type: 'supports',
      description: 'Metric choice affects detection',
    },
    {
      source: '2503.05788',
      target: '2305.18654',
      type: 'supports',
      description: 'Memorization vs generalization',
    },
    {
      source: '2501.02497',
      target: '2510.18254',
      type: 'supports',
      description: 'Self-correction limited',
    },
    {
      source: '2501.02497',
      target: '2506.17219',
      type: 'supports',
      description: 'RL limited effectiveness',
    },
    {
      source: '2404.00560',
      target: '2407.20311',
      type: 'supports',
      description: 'LG achievable with proper structure',
    },
    {
      source: '2404.00560',
      target: '2305.18654',
      type: 'supports',
      description: 'Standard formulations fail',
    },
    {
      source: '2510.10182',
      target: '2305.18654',
      type: 'supports',
      description: 'Pattern matching mechanism',
    },
    {
      source: '2510.10182',
      target: '2506.18880',
      type: 'supports',
      description: 'Compositional generalization failures',
    },
    {
      source: '2510.15974',
      target: '2506.06941',
      type: 'supports',
      description: "Collapse pattern; tools don't help",
    },
    {
      source: '2510.15974',
      target: '2506.18957',
      type: 'rebuts',
      description: "Agentic framework doesn't solve",
    },
    {
      source: '2510.15974',
      target: '2507.17699',
      type: 'rebuts',
      description: "Environment interface doesn't help",
    },
    {
      source: '2504.01445',
      target: '2305.18654',
      type: 'supports',
      description: 'Compositional reasoning failure',
    },
    {
      source: '2504.01445',
      target: '2506.18880',
      type: 'supports',
      description: 'Primitives succeed, compositions fail',
    },
    {
      source: '2504.01445',
      target: '2601.14456',
      type: 'supports',
      description: 'Similar ID/OOD gap',
    },
    {
      source: '2504.12523',
      target: '2305.18654',
      type: 'supports',
      description: "Can't apply learned patterns",
    },
    {
      source: '2504.12523',
      target: '2504.01445',
      type: 'supports',
      description: "Can pattern match, can't compose",
    },
    {
      source: '2512.13713',
      target: '2506.06941',
      type: 'challenges',
      description: 'O3 develops meta-cognitive strategies',
    },
    {
      source: '2512.13713',
      target: '2510.15974',
      type: 'supports',
      description: 'Most models still fail/loop',
    },
    {
      source: '2510.09312',
      target: '2510.22362',
      type: 'supports',
      description: 'Mechanistic distinction',
    },
    {
      source: '2509.01267',
      target: '2410.05229',
      type: 'supports',
      description: 'Struggle with rule variations',
    },
    {
      source: '2509.01267',
      target: '2504.01445',
      type: 'supports',
      description: 'Systematicity failures',
    },
    {
      source: '2506.15629',
      target: '2305.18654',
      type: 'supports',
      description: 'Follow learned patterns over instructions',
    },
    {
      source: '2506.15629',
      target: '2504.01445',
      type: 'supports',
      description: 'Compositional generalization failure',
    },
    {
      source: '2601.03676',
      target: '2305.18654',
      type: 'supports',
      description: 'Power-law explains compositional scarcity',
    },
    {
      source: '2601.03676',
      target: '2504.01445',
      type: 'supports',
      description: 'Data bottleneck k>1',
    },
    {
      source: '2601.03676',
      target: '2506.18880',
      type: 'supports',
      description: 'Compositional collapse',
    },
    {
      source: '2505.16782',
      target: '2307.13702',
      type: 'supports',
      description: 'CoT unfaithfulness problem',
    },
    {
      source: '2505.16782',
      target: '2601.08058',
      type: 'supports',
      description: 'Latent reasoning modes',
    },
    {
      source: '2502.07813',
      target: '2305.18654',
      type: 'supports',
      description: 'Compositional failures',
    },
    {
      source: '2502.07813',
      target: '2506.18880',
      type: 'supports',
      description: 'Primitives succeed, compositions fail',
    },
    {
      source: '2510.27378',
      target: '2307.13702',
      type: 'extends',
      description: 'Verbosity dimension',
    },
    {
      source: '2510.27378',
      target: '2505.05410',
      type: 'supports',
      description: "CoT doesn't reflect reasoning",
    },
    {
      source: '2403.11793',
      target: '2305.18654',
      type: 'supports',
      description: 'Compositional reasoning failure',
    },
    {
      source: '2403.11793',
      target: '2506.18880',
      type: 'supports',
      description: 'Primitives work, compositions fail',
    },
    {
      source: '2504.00294',
      target: '2501.02497',
      type: 'supports',
      description: 'Task-dependent scaling',
    },
    {
      source: '2504.00294',
      target: '2506.06941',
      type: 'supports',
      description: 'Complexity collapse persists',
    },
    // Paper #84: Trapped in the Past (2601.16823)
    {
      source: '2601.16823',
      target: '2305.18654',
      type: 'supports',
      description: 'Crystallized (memorization) dominates reasoning',
    },
    {
      source: '2601.16823',
      target: '2506.06941',
      type: 'supports',
      description: 'OOD collapse to random performance',
    },
    {
      source: '2601.16823',
      target: '2512.07783',
      type: 'supports',
      description: 'Reasoning tokens diminishing returns OOD',
    },
    {
      source: '2601.16823',
      target: '2601.14456',
      type: 'supports',
      description: 'ID/OOD gap pattern in chess',
    },
    // Paper #85: ToM Robustness (2601.16853)
    {
      source: '2601.16853',
      target: '2512.07783',
      type: 'supports',
      description: 'Robustness bounded by base model capability',
    },
    {
      source: '2601.16853',
      target: '2501.12948',
      type: 'supports',
      description: 'RL surfaces existing capability',
    },
    // Paper #86: MortalMATH (2601.18790)
    {
      source: '2601.18790',
      target: '2501.12948',
      type: 'challenges',
      description: 'RLVR creates tunnel vision, not reasoning',
    },
    {
      source: '2601.18790',
      target: '2506.17219',
      type: 'supports',
      description: 'RL optimization creates blindness',
    },
    {
      source: '2601.18790',
      target: '2305.18654',
      type: 'supports',
      description: 'Pattern pursuit ignores context',
    },
    // Missing papers added
    {
      source: '2406.10625',
      target: '2307.13702',
      type: 'extends',
      description: 'Faithfulness-accuracy tradeoff',
    },
    {
      source: '2406.10625',
      target: '2505.05410',
      type: 'supports',
      description: 'Larger models less faithful',
    },
    {
      source: '2510.10182',
      target: '2305.18654',
      type: 'supports',
      description: 'Induction heads = pattern matching',
    },
    {
      source: '2512.01222',
      target: '2601.08058',
      type: 'supports',
      description: 'Internal representations interpretable',
    },
    {
      source: '2601.14716',
      target: '2501.12948',
      type: 'supports',
      description: 'RL improves long-CoT reasoning',
    },
    {
      source: '2601.14716',
      target: '2512.07783',
      type: 'supports',
      description: 'Depends on distillation (surfacing)',
    },
    // o3 Thinks Harder Not Longer links
    {
      source: '2502.15631',
      target: '2506.06941',
      type: 'supports',
      description: 'More tokens ≠ better outcomes',
    },
    {
      source: '2502.15631',
      target: '2305.18654',
      type: 'supports',
      description: 'Error accumulation with chain length',
    },
    {
      source: '2502.15631',
      target: '2504.09858',
      type: 'supports',
      description: 'Excessive reasoning can hurt',
    },
    {
      source: '2502.15631',
      target: '2501.02497',
      type: 'supports',
      description: 'Explains why sequential scaling fails',
    },
    {
      source: '2502.15631',
      target: '2501.19393',
      type: 'challenges',
      description: 'Accuracy declines with length (vs log-linear claim)',
    },
    // System 1/2 Alignment links
    {
      source: '2502.12470',
      target: '2502.15631',
      type: 'supports',
      description: 'Longer reasoning not always better',
    },
    {
      source: '2502.12470',
      target: '2506.06941',
      type: 'supports',
      description: 'Overthinking problematic',
    },
    {
      source: '2502.12470',
      target: '2504.09858',
      type: 'supports',
      description: 'Explicit reasoning sometimes suboptimal',
    },
    {
      source: '2502.12470',
      target: '2512.07783',
      type: 'supports',
      description: 'Capabilities from training distribution',
    },
    // Content Effects on Reasoning links
    {
      source: '2207.07051',
      target: '2305.18654',
      type: 'supports',
      description: 'Distribution-bounded reasoning',
    },
    {
      source: '2207.07051',
      target: '2410.05229',
      type: 'supports',
      description: 'Content/framing affects performance',
    },
    {
      source: '2207.07051',
      target: '2512.07783',
      type: 'supports',
      description: 'Capabilities from training distribution',
    },
    {
      source: '2207.07051',
      target: '2410.13343',
      type: 'supports',
      description: 'Models exploit semantic shortcuts',
    },
    {
      source: '2207.07051',
      target: '2502.12470',
      type: 'extends',
      description: 'Dual-process with human comparison',
    },
    // AI Metacognition links
    {
      source: '2411.02478',
      target: '2506.06941',
      type: 'supports',
      description: 'Both show AI lacks genuine reasoning at complexity thresholds',
    },
    {
      source: '2411.02478',
      target: '2207.07051',
      type: 'supports',
      description: 'Both show AI relies on learned patterns',
    },
    {
      source: '2411.02478',
      target: '2410.05229',
      type: 'supports',
      description: 'Lack of metacognition explains perturbation sensitivity',
    },
    {
      source: '2411.02478',
      target: '2501.02497',
      type: 'supports',
      description: 'Self-correction limited without metacognition',
    },
    {
      source: '2411.02478',
      target: '2510.18254',
      type: 'supports',
      description: 'Reflection without metacognition is hollow',
    },
    {
      source: '2411.02478',
      target: '2502.12470',
      type: 'extends',
      description: 'Metacognition = ability to switch S1/S2 appropriately',
    },
    {
      source: '2411.02478',
      target: '2502.15631',
      type: 'extends',
      description: 'Wise AI would know when to think longer vs stop',
    },
    // Temporal Cognition links
    {
      source: '2507.15851',
      target: '2207.07051',
      type: 'supports',
      description: 'Both show LLMs learn patterns from data that mirror human cognition',
    },
    {
      source: '2507.15851',
      target: '2512.07783',
      type: 'supports',
      description: 'Both show capabilities emerge from training distribution',
    },
    {
      source: '2507.15851',
      target: '2512.23722',
      type: 'supports',
      description: 'Both show LLMs build internal models from training signal',
    },
    {
      source: '2507.15851',
      target: '2502.12470',
      type: 'extends',
      description: 'Adds temporal dimension to dual-process understanding',
    },
    {
      source: '2507.15851',
      target: '2503.05788',
      type: 'extends',
      description: 'Provides mechanistic example of emergent ability',
    },
  ],
};
