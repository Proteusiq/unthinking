# Papers to Read

New papers discovered by automated search. Qualified as LLM reasoning papers and checked for relevance to thesis.

**Last updated**: 2026-01-24
**Papers found**: 141

---

## 2026-01-24

### [Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation](https://arxiv.org/abs/2601.14691v2)
- **arXiv**: 2601.14691v2
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 10/10
- **Why read**: Thesis-relevant: unfaithful
- **Abstract**: Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM j...

### [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392v1)
- **arXiv**: 2601.13392v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 10/10
- **Why read**: Thesis-relevant: pattern matching
- **Abstract**: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, an...

### [Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2601.15652v1)
- **arXiv**: 2601.15652v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 10/10
- **Why read**: Thesis-relevant: unfaithful
- **Abstract**: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines n...

### [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995v1)
- **arXiv**: 2601.12995v1
- **Published**: 2026-01-19
- **Stance**: CHALLENGES
- **Priority**: 9/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based op...

### [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053v1)
- **arXiv**: 2601.14053v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 9/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dime...

### [Iterative Refinement Improves Compositional Image Generation](https://arxiv.org/abs/2601.15286v1)
- **arXiv**: 2601.15286v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 9/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, thought
- **Abstract**: Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where...

### [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158v1)
- **arXiv**: 2601.15158v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 9/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on...

### [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://arxiv.org/abs/2601.15487v1)
- **arXiv**: 2601.15487v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 8/10
- **Why read**: Thesis-relevant: faithfulness, mirage
- **Abstract**: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning re...

### [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457v1)
- **arXiv**: 2601.15457v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 8/10
- **Why read**: Thesis-relevant: faithfulness
- **Abstract**: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical ...

### [Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning](https://arxiv.org/abs/2601.14750v2)
- **arXiv**: 2601.14750v2
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 8/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzabilit...

### [Say Anything but This: When Tokenizer Betrays Reasoning in LLMs](https://arxiv.org/abs/2601.14658v1)
- **arXiv**: 2601.14658v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 8/10
- **Why read**: Thesis-relevant: illusion, surface
- **Abstract**: Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct "words" even when they are sem...

### [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538v1)
- **arXiv**: 2601.12538v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 8/10
- **Why read**: General reasoning paper. Keywords: reasoning, thought, inference
- **Abstract**: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. I...

### [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243v1)
- **arXiv**: 2601.13243v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 8/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model gener...

### [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160v1)
- **arXiv**: 2601.15160v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 7/10
- **Why read**: General reasoning paper. Keywords: reasoning, large language model, language model
- **Abstract**: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we ...

### ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992v1)
- **arXiv**: 2601.13992v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 7/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit di...

### [Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring](https://arxiv.org/abs/2601.13879v2)
- **arXiv**: 2601.13879v2
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 7/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: While Chain-of-Thought (CoT) reasoning significantly enhances the performance of Multimodal Large Language Models (MLLMs), its autoregressive nature incurs prohibitive latency constraints. Current efforts to mitigate this via token compression often fail by blindly applying text-centric metrics to multimodal contexts. We identify a critical failure mode termed Visual Amnesia, where linguistically ...

### [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770v1)
- **arXiv**: 2601.13770v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 7/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization...

### [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742v1)
- **arXiv**: 2601.13742v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 7/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achi...

### [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443v1)
- **arXiv**: 2601.13443v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 7/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse...

### [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284v1)
- **arXiv**: 2601.13284v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 7/10
- **Why read**: Thesis-relevant: distribution shift
- **Abstract**: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised f...

### [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488v1)
- **arXiv**: 2601.15488v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, inference
- **Abstract**: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewp...

### [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479v1)
- **arXiv**: 2601.15479v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: chain-of-thought, cot, thought
- **Abstract**: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text con...

### [Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions](https://arxiv.org/abs/2601.15267v1)
- **arXiv**: 2601.15267v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoni...

### [The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models](https://arxiv.org/abs/2601.15165v1)
- **arXiv**: 2601.15165v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have l...

### [AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering](https://arxiv.org/abs/2601.14728v1)
- **arXiv**: 2601.14728v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Although text-to-audio generation has made remarkable progress in realism and diversity, the development of evaluation metrics has not kept pace. Widely-adopted approaches, typically based on embedding similarity like CLAPScore, effectively measure general relevance but remain limited in fine-grained semantic alignment and compositional reasoning. To address this, we introduce AQAScore, a backbone...

### [Rewarding How Models Think Pedagogically: Integrating Pedagogical Reasoning and Thinking Rewards for LLMs in Education](https://arxiv.org/abs/2601.14560v1)
- **arXiv**: 2601.14560v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, llm
- **Abstract**: Large language models (LLMs) are increasingly deployed as intelligent tutoring systems, yet research on optimizing LLMs specifically for educational contexts remains limited. Recent works have proposed reinforcement learning approaches for training LLM tutors, but these methods focus solely on optimizing visible responses while neglecting the model's internal thinking process. We introduce Pedagog...

### [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v1)
- **arXiv**: 2601.14249v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, cot
- **Abstract**: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student lik...

### [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243v1)
- **arXiv**: 2601.14243v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottle...

### [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209v1)
- **arXiv**: 2601.14209v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in faile...

### [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127v1)
- **arXiv**: 2601.14127v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: Thesis-relevant: superficial
- **Abstract**: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 ...

### [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063v1)
- **arXiv**: 2601.14063v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)...

### [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041v1)
- **arXiv**: 2601.14041v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, llm
- **Abstract**: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptu...

### [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919v1)
- **arXiv**: 2601.13919v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, language model
- **Abstract**: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated ...

### [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690v1)
- **arXiv**: 2601.13690v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at ...

### [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387v1)
- **arXiv**: 2601.13387v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: Thesis-relevant: superficial
- **Abstract**: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods...

### [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368v1)
- **arXiv**: 2601.13368v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, thought
- **Abstract**: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning ...

### [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155v1)
- **arXiv**: 2601.13155v1
- **Published**: 2026-01-19
- **Stance**: CHALLENGES
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, thought, inference
- **Abstract**: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accura...

### [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812v1)
- **arXiv**: 2601.12812v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptabi...

### [SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding](https://arxiv.org/abs/2601.12805v2)
- **arXiv**: 2601.12805v2
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale ge...

### [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648v1)
- **arXiv**: 2601.12648v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: chain-of-thought, thought, inference
- **Abstract**: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought...

### [HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation](https://arxiv.org/abs/2601.14598v1)
- **arXiv**: 2601.14598v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured...

### [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581v1)
- **arXiv**: 2601.13581v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. I...

### [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383v1)
- **arXiv**: 2601.13383v1
- **Published**: 2026-01-19
- **Stance**: CHALLENGES
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source...

### [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781v1)
- **arXiv**: 2601.12781v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and stro...

### [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499v1)
- **arXiv**: 2601.12499v1
- **Published**: 2026-01-18
- **Stance**: SUPPORTS
- **Priority**: 6/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, llm
- **Abstract**: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semant...

### [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588v1)
- **arXiv**: 2601.15588v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference co...

### [Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge](https://arxiv.org/abs/2601.15495v1)
- **arXiv**: 2601.15495v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus onl...

### [RSNA Large Language Model Benchmark Dataset for Chest Radiographs of Cardiothoracic Disease: Radiologist Evaluation and Validation Enhanced by AI Labels (REVEAL-CXR)](https://arxiv.org/abs/2601.15129v1)
- **arXiv**: 2601.15129v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Multimodal large language models have demonstrated comparable performance to that of radiology trainees on multiple-choice board-style exams. However, to develop clinically useful multimodal LLM tools, high-quality benchmarks curated by domain experts are essential. To curate released and holdout datasets of 100 chest radiographic studies each and propose an artificial intelligence (AI)-assisted e...

### [The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution](https://arxiv.org/abs/2601.15075v1)
- **arXiv**: 2601.15075v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \textit{fai...

### [LogicScore: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering](https://arxiv.org/abs/2601.15050v2)
- **arXiv**: 2601.15050v2
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Current evaluation methods for Attributed Question Answering (AQA) suffer from \textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate th...

### [CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning](https://arxiv.org/abs/2601.14952v1)
- **arXiv**: 2601.14952v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a "sparse retrieval" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evi...

### [What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study](https://arxiv.org/abs/2601.14888v1)
- **arXiv**: 2601.14888v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) f...

### [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716v1)
- **arXiv**: 2601.14716v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model ...

### [Can LLM Reasoning Be Trusted? A Comparative Study: Using Human Benchmarking on Statistical Tasks](https://arxiv.org/abs/2601.14479v1)
- **arXiv**: 2601.14479v1
- **Published**: 2026-01-20
- **Stance**: CHALLENGES
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: This paper investigates the ability of large language models (LLMs) to solve statistical tasks, as well as their capacity to assess the quality of reasoning. While state-of-the-art LLMs have demonstrated remarkable performance in a range of NLP tasks, their competence in addressing even moderately complex statistical challenges is not well understood. We have fine-tuned selected open-source LLMs o...

### [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836v1)
- **arXiv**: 2601.13836v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. T...

### [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453v1)
- **arXiv**: 2601.13453v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce Physic...

### [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300v1)
- **arXiv**: 2601.13300v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question ...

### [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262v1)
- **arXiv**: 2601.13262v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a ...

### [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115v1)
- **arXiv**: 2601.13115v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generat...

### [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269v1)
- **arXiv**: 2601.12269v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ...

### [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799v1)
- **arXiv**: 2601.12799v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: chain-of-thought, thought, gpt
- **Abstract**: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and...

### [Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents](https://arxiv.org/abs/2601.15816v1)
- **arXiv**: 2601.15816v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solut...

### [From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.15690v1)
- **arXiv**: 2601.15690v1
- **Published**: 2026-01-22
- **Stance**: CHALLENGES
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an acti...

### [TransportAgents: a multi-agents LLM framework for traffic accident severity prediction](https://arxiv.org/abs/2601.15519v1)
- **arXiv**: 2601.15519v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes...

### [Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding](https://arxiv.org/abs/2601.15482v1)
- **arXiv**: 2601.15482v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This pa...

### [MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs](https://arxiv.org/abs/2601.15279v1)
- **arXiv**: 2601.15279v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or rea...

### [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711v1)
- **arXiv**: 2601.14711v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. ...

### [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887v1)
- **arXiv**: 2601.13887v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, llm
- **Abstract**: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computation...

### [Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference](https://arxiv.org/abs/2601.15333v1)
- **arXiv**: 2601.15333v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation pro...

### [TruthTensor: Evaluating LLMs through Human Imitation on Prediction Market under Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545v2)
- **arXiv**: 2601.13545v2
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: Thesis-relevant: distribution shift
- **Abstract**: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures reasoning models not only as prediction engi...

### [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481v1)
- **arXiv**: 2601.13481v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion a...

### [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206v1)
- **arXiv**: 2601.13206v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to inve...

### [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842v1)
- **arXiv**: 2601.12842v1
- **Published**: 2026-01-19
- **Stance**: CHALLENGES
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote...

### [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560v1)
- **arXiv**: 2601.12560v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already suppor...

### [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444v1)
- **arXiv**: 2601.12444v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning ...

### [CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning](https://arxiv.org/abs/2601.15141v1)
- **arXiv**: 2601.15141v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise lea...

### [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549v1)
- **arXiv**: 2601.14549v1
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, inference, llm
- **Abstract**: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must ...

### [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653v1)
- **arXiv**: 2601.13653v1
- **Published**: 2026-01-20
- **Stance**: CHALLENGES
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of st...

### [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988v1)
- **arXiv**: 2601.12988v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered promptin...

### [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807v1)
- **arXiv**: 2601.12807v1
- **Published**: 2026-01-19
- **Stance**: CHALLENGES
- **Priority**: 5/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particula...

### [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892v1)
- **arXiv**: 2601.15892v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training ...

### [ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models](https://arxiv.org/abs/2601.15812v1)
- **arXiv**: 2601.15812v1
- **Published**: 2026-01-22
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM...

### [PhysProver: Advancing Automatic Theorem Proving for Physics](https://arxiv.org/abs/2601.15737v1)
- **arXiv**: 2601.15737v1
- **Published**: 2026-01-22
- **Stance**: CHALLENGES
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, generalization
- **Abstract**: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. Ho...

### [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645v1)
- **arXiv**: 2601.15645v1
- **Published**: 2026-01-22
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. W...

### [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429v1)
- **arXiv**: 2601.15429v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets m...

### [The Effect of Scripts and Formats on LLM Numeracy](https://arxiv.org/abs/2601.15251v1)
- **arXiv**: 2601.15251v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large language models (LLMs) have achieved impressive proficiency in basic arithmetic, rivaling human-level performance on standard numerical tasks. However, little attention has been given to how these models perform when numerical expressions deviate from the prevailing conventions present in their training corpora. In this work, we investigate numerical reasoning across a wide range of numeral ...

### [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862v1)
- **arXiv**: 2601.14862v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, language model
- **Abstract**: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evalu...

### [DARL: Encouraging Diverse Answers for General Reasoning without Verifiers](https://arxiv.org/abs/2601.14700v1)
- **arXiv**: 2601.14700v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, large language model, language model
- **Abstract**: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated promising gains in enhancing the reasoning capabilities of large language models. However, its dependence on domain-specific verifiers significantly restricts its applicability to open and general domains. Recent efforts such as RLPR have extended RLVR to general domains, enabling training on broader datasets and achieving impr...

### [AdaTIR: Adaptive Tool-Integrated Reasoning via Difficulty-Aware Policy Optimization](https://arxiv.org/abs/2601.14696v1)
- **arXiv**: 2601.14696v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Tool-Integrated Reasoning (TIR) has significantly enhanced the capabilities of Large Language Models (LLMs), yet current agents tend to exhibit cognitive offloading, redundantly invoking external tools even for simple tasks. In this paper, we suggest that true agentic intelligence requires not just tool invocation, but the adaptive wisdom to discern when to use them. We propose AdaTIR, a framework...

### [Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis](https://arxiv.org/abs/2601.14637v1)
- **arXiv**: 2601.14637v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data explor...

### [VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration](https://arxiv.org/abs/2601.14440v1)
- **arXiv**: 2601.14440v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, thought
- **Abstract**: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagram...

### [A model of errors in transformers](https://arxiv.org/abs/2601.14175v1)
- **arXiv**: 2601.14175v1
- **Published**: 2026-01-20
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, transformer
- **Abstract**: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexi...

### [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160v1)
- **arXiv**: 2601.14160v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable ...

### [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084v1)
- **arXiv**: 2601.14084v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal mod...

### [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007v1)
- **arXiv**: 2601.14007v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract prin...

### [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761v2)
- **arXiv**: 2601.13761v2
- **Published**: 2026-01-20
- **Stance**: CHALLENGES
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Sol...

### [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717v1)
- **arXiv**: 2601.13717v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, chain-of-thought, thought
- **Abstract**: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress...

### [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979v1)
- **arXiv**: 2601.12979v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agent...

### [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974v1)
- **arXiv**: 2601.12974v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluat...

### [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771v1)
- **arXiv**: 2601.12771v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning app...

### [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748v1)
- **arXiv**: 2601.12748v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, ...

### [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618v1)
- **arXiv**: 2601.12618v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces gene...

### [Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline](https://arxiv.org/abs/2601.12307v1)
- **arXiv**: 2601.12307v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, inference
- **Abstract**: Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether...

### [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://arxiv.org/abs/2601.16027v1)
- **arXiv**: 2601.16027v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: inference, llm, large language model
- **Abstract**: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retr...

### [Autonomous Business System via Neuro-symbolic AI](https://arxiv.org/abs/2601.15599v1)
- **arXiv**: 2601.15599v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To add...

### [Tokenomics: Quantifying Where Tokens Are Used in Agentic Software Engineering](https://arxiv.org/abs/2601.14470v1)
- **arXiv**: 2601.14470v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, gpt
- **Abstract**: LLM-based Multi-Agent (LLM-MA) systems are increasingly applied to automate complex software engineering tasks such as requirements engineering, code generation, and testing. However, their operational efficiency and resource consumption remain poorly understood, hindering practical adoption due to unpredictable costs and environmental impact. To address this, we conduct an analysis of token consu...

### [Agentic AI Meets Edge Computing in Autonomous UAV Swarms](https://arxiv.org/abs/2601.14437v1)
- **arXiv**: 2601.14437v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: The integration of agentic AI, powered by large language models (LLMs) with autonomous reasoning, planning, and execution, into unmanned aerial vehicle (UAV) swarms opens new operational possibilities and brings the vision of the Internet of Drones closer to reality. However, infrastructure constraints, dynamic environments, and the computational demands of multi-agent coordination limit real-worl...

### [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880v1)
- **arXiv**: 2601.13880v1
- **Published**: 2026-01-20
- **Stance**: CHALLENGES
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a la...

### [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398v1)
- **arXiv**: 2601.13398v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free...

### [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186v1)
- **arXiv**: 2601.13186v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth ...

### [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711v1)
- **arXiv**: 2601.12711v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically ...

### [Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition](https://arxiv.org/abs/2601.12522v1)
- **arXiv**: 2601.12522v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and...

### [AgenTRIM: Tool Risk Mitigation for Agentic AI](https://arxiv.org/abs/2601.12449v1)
- **arXiv**: 2601.12449v1
- **Published**: 2026-01-18
- **Stance**: SUPPORTS
- **Priority**: 4/10
- **Why read**: Thesis-relevant: surface
- **Abstract**: AI agents are autonomous systems that combine LLMs with external tools to solve complex tasks. While such tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. We characterize these failures as unbalanced tool-driven agency. Agents may retain unnecessary permissions (excessive agency) or fail to invoke required tools (insuffi...

### [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323v1)
- **arXiv**: 2601.12323v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimiza...

### [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259v1)
- **arXiv**: 2601.12259v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficien...

### [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892v1)
- **arXiv**: 2601.13892v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front e...

### [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355v1)
- **arXiv**: 2601.12355v1
- **Published**: 2026-01-18
- **Stance**: BALANCED
- **Priority**: 4/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, large language model
- **Abstract**: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optim...

### [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708v1)
- **arXiv**: 2601.15708v1
- **Published**: 2026-01-22
- **Stance**: CHALLENGES
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, language model
- **Abstract**: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on th...

### [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918v1)
- **arXiv**: 2601.13918v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, large language model, language model
- **Abstract**: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to...

### [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591v1)
- **arXiv**: 2601.13591v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, gpt
- **Abstract**: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 28...

### [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433v1)
- **arXiv**: 2601.13433v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, large language model, language model
- **Abstract**: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal,...

### [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465v1)
- **arXiv**: 2601.12465v1
- **Published**: 2026-01-18
- **Stance**: SUPPORTS
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, reinforcement learning
- **Abstract**: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this fai...

### [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599v1)
- **arXiv**: 2601.14599v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, thinking, llm
- **Abstract**: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it ...

### [Reasoning is a Modality](https://arxiv.org/abs/2601.13562v1)
- **arXiv**: 2601.13562v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, transformer
- **Abstract**: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavi...

### [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546v1)
- **arXiv**: 2601.13546v1
- **Published**: 2026-01-20
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, generalization
- **Abstract**: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasonin...

### [Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems](https://arxiv.org/abs/2601.15676v1)
- **arXiv**: 2601.15676v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 3/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm, language model
- **Abstract**: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy r...

### [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018v1)
- **arXiv**: 2601.16018v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downs...

### [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593v1)
- **arXiv**: 2601.15593v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100...

### [PROGRESSLM: Towards Progress Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.15224v1)
- **arXiv**: 2601.15224v1
- **Published**: 2026-01-21
- **Stance**: CHALLENGES
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: Estimating task progress requires reasoning over long-horizon dynamics rather than recognizing static visual content. While modern Vision-Language Models (VLMs) excel at describing what is visible, it remains unclear whether they can infer how far a task has progressed from partial observations. To this end, we introduce Progress-Bench, a benchmark for systematically evaluating progress reasoning ...

### [PodBench: A Comprehensive Benchmark for Instruction-Aware Audio-Oriented Podcast Script Generation](https://arxiv.org/abs/2601.14903v1)
- **arXiv**: 2601.14903v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Podcast script generation requires LLMs to synthesize structured, context-grounded dialogue from diverse inputs, yet systematic evaluation resources for this task remain limited. To bridge this gap, we introduce PodBench, a benchmark comprising 800 samples with inputs up to 21K tokens and complex multi-speaker instructions. We propose a multifaceted evaluation framework that integrates quantitativ...

### [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758v2)
- **arXiv**: 2601.14758v2
- **Published**: 2026-01-21
- **Stance**: SUPPORTS
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repacka...

### [ClaimDB: A Fact Verification Benchmark over Large Structured Data](https://arxiv.org/abs/2601.14698v1)
- **arXiv**: 2601.14698v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from gov...

### [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806v1)
- **arXiv**: 2601.13806v1
- **Published**: 2026-01-20
- **Stance**: CHALLENGES
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-train...

### [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228v1)
- **arXiv**: 2601.13228v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To addres...

### [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183v1)
- **arXiv**: 2601.13183v1
- **Published**: 2026-01-19
- **Stance**: SUPPORTS
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, language model
- **Abstract**: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and...

### [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639v1)
- **arXiv**: 2601.12639v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimizatio...

### [Replicating Human Motivated Reasoning Studies with LLMs](https://arxiv.org/abs/2601.16130v1)
- **arXiv**: 2601.16130v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expect...

### [VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management](https://arxiv.org/abs/2601.15798v1)
- **arXiv**: 2601.15798v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring ...

### [AgentSM: Semantic Memory for Agentic Text-to-SQL](https://arxiv.org/abs/2601.15709v1)
- **arXiv**: 2601.15709v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeatin...

### [Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems](https://arxiv.org/abs/2601.14662v1)
- **arXiv**: 2601.14662v1
- **Published**: 2026-01-21
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box settin...

### [IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks](https://arxiv.org/abs/2601.13114v1)
- **arXiv**: 2601.13114v1
- **Published**: 2026-01-19
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm
- **Abstract**: Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent to...

---
