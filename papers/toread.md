# Papers to Read

New papers discovered by automated search. Qualified as LLM reasoning papers and checked for relevance to thesis.

**Last updated**: 2026-01-25
**Papers found**: 2

---

## 2026-01-25

### [TEST: Fake Paper for Workflow Testing](https://arxiv.org/abs/0000.00000)
- **arXiv**: 0000.00000
- **Published**: 2026-01-25
- **Stance**: SUPPORTS
- **Priority**: 10/10
- **Why read**: This is a fake paper to test the workflow issue creation with collapsible abstracts

<details>
<summary>Abstract</summary>

This is a fake abstract to test that the GitHub Actions workflow correctly extracts paper metadata including the title, stance, why read, and abstract fields. The abstract should appear in a collapsible details block in the created issue. If you see this, the workflow is working correctly!

</details>

### [Replicating Human Motivated Reasoning Studies with LLMs](https://arxiv.org/abs/2601.16130v1)
- **arXiv**: 2601.16130v1
- **Published**: 2026-01-22
- **Stance**: BALANCED
- **Priority**: 2/10
- **Why read**: General reasoning paper. Keywords: reasoning, llm

<details>
<summary>Abstract</summary>

Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.

</details>

---
