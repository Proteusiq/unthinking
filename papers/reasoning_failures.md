# Papers from LLM Reasoning Failures Survey

Source: [arXiv:2602.06176](https://arxiv.org/abs/2602.06176) - Song, Han, Goodman (TMLR 2026)
GitHub: https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures

**Last updated**: 2026-02-11
**Tracking Issues**: #48-55

---

## Status Legend

- âœ… DONE - Already analyzed in our corpus
- ğŸ“‹ TO-READ - In toread.md (Issues #48-54)
- âŒ MISSING - Not yet in our corpus (Issue #55)

---

## Surveys

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âœ… DONE | 2602.06176 | Large Language Model Reasoning Failures | TMLR 2026 |
| âŒ MISSING | 2503.13657 | Why Do Multi-Agent LLM Systems Fail? | NeurIPS 2025 |

---

## Informal Reasoning - Individual Cognitive Skills and Biases

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| ğŸ“‹ TO-READ | 2305.03731 | Working memory capacity of ChatGPT | AAAI 2024 |
| âŒ MISSING | - | Working memory identifies reasoning limits in language models | EMNLP 2024 |
| âŒ MISSING | - | Self-Attention Limits Working Memory Capacity of Transformer-Based Models | NeurIPS 2024 Workshop |
| âŒ MISSING | - | Unable to Forget: Proactive Interference Reveals Working Memory Limits | ICML 2025 Workshop |
| ğŸ“‹ TO-READ | 2505.10571 | LLMs Do Not Have Human-Like Working Memory | arXiv |
| âŒ MISSING | - | Working memory attack on LLMs | ICLR 2025 Workshop |
| âœ… DONE | 2409.15454 | In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors | EMNLP 2024 |
| âŒ MISSING | - | Deficient Executive Control in Transformer Attention | bioRxiv |
| âŒ MISSING | - | Cognitive flexibility of large language models | ICML 2024 Workshop |
| âŒ MISSING | - | LLMs and the Abstraction and Reasoning Corpus | TMLR 2024 |
| ğŸ“‹ TO-READ | 2305.19555 | Large language models are not strong abstract reasoners | arXiv |
| ğŸ“‹ TO-READ | 2410.11756 | Evidence of Cognitive Deficits: Clock Drawing Test Analysis | arXiv |
| ğŸ“‹ TO-READ | 2502.05092 | Lost in Time: Clock and Calendar Understanding Challenges | arXiv |
| âœ… DONE | 2207.07051 | Language models, like humans, show content effects on reasoning | PNAS Nexus 2024 |
| âŒ MISSING | - | Confirmation and Specificity Biases in Large Language Models | IEEE Intelligent Systems |
| âŒ MISSING | - | Unveiling Confirmation Bias in Chain-of-Thought Reasoning | ACL 2025 |
| âŒ MISSING | - | Conformity in Large Language Models | ACL 2025 |
| ğŸ“‹ TO-READ | 2412.04629 | Argumentative Experience: Reducing Confirmation Bias | arXiv |
| ğŸ“‹ TO-READ | 2410.15413 | A Comprehensive Evaluation of Cognitive Biases in LLMs | arXiv |
| ğŸ“‹ TO-READ | 2403.00811 | Cognitive bias in high-stakes decision-making with LLMs | EMNLP 2024 |
| âœ… DONE | 2408.00137 | Correcting negative bias through negative attention score alignment | arXiv |
| âœ… DONE | 2202.12299 | Capturing failures of large language models via human cognitive biases | NeurIPS 2022 |
| ğŸ“‹ TO-READ | 2305.04400 | Do large language models show decision heuristics similar to humans? | J Exp Psych 2024 |
| âŒ MISSING | - | Human bias in AI models? Anchoring effects and mitigation strategies | J Behavioral & Exp Finance |
| âŒ MISSING | - | An Anchoring Effect in Large Language Models | IEEE Intelligent Systems 2025 |
| ğŸ“‹ TO-READ | 2505.15392 | An Empirical Study of the Anchoring Effect in LLMs | arXiv |
| ğŸ“‹ TO-READ | 2504.09946 | Assessing Judging Bias in Large Reasoning Models | arXiv |
| ğŸ“‹ TO-READ | 2502.17091 | WildFrame: Comparing Framing in Humans and LLMs | arXiv |
| ğŸ“‹ TO-READ | 2503.04840 | Framing the Game: How Context Shapes LLM Decision-Making | arXiv |
| âŒ MISSING | - | Investigating bias in LLM-based bias detection | COLING 2025 |
| ğŸ“‹ TO-READ | 2506.03923 | More or Less Wrong: Directional Bias in LLM Comparative Reasoning | arXiv |
| ğŸ“‹ TO-READ | 2310.10076 | Verbosity bias in preference labeling by large language models | arXiv |
| ğŸ“‹ TO-READ | 2505.22910 | Talent or Luck? Evaluating Attribution Bias in LLMs | arXiv |
| ğŸ“‹ TO-READ | 2406.01285 | Large language models as recommender systems: Popularity bias | arXiv |
| âŒ MISSING | - | Beyond Utility: Evaluating LLM as Recommender | WWW 2025 |
| ğŸ“‹ TO-READ | 2507.22887 | Where to show Demos in Your Prompt: Positional Bias | arXiv |
| âœ… DONE | 2308.11483 | Large language models sensitivity to the order of options | NAACL 2024 |
| âŒ MISSING | - | Mitigating order sensitivity in large language models | IJAIRD 2024 |
| ğŸ“‹ TO-READ | 2502.04134 | The Order Effect: Investigating Prompt Sensitivity to Input Order | KDD 2025 Workshop |
| ğŸ“‹ TO-READ | 2412.06593 | Anchoring Bias in Large Language Models: An Experimental Study | arXiv |
| âŒ MISSING | - | Believing Anthropomorphism: Trust in Large Language Models | CHI 2024 |
| âœ… DONE | 2309.17012 | Benchmarking cognitive biases in large language models as evaluators | ACL 2024 |
| âœ… DONE | 2302.00093 | Large Language Models Can Be Easily Distracted by Irrelevant Context | ICML 2023 |
| âœ… DONE | 2308.00225 | Instructed to bias: emergent cognitive bias in instruction-tuned LMs | TACL 2024 |
| âœ… DONE | 2303.13988 | Machine psychology: Investigating emergent capabilities | arXiv |
| âŒ MISSING | - | Cognitive LLMs: Human-Like AI for Manufacturing Decision-making | Neurosymbolic AI 2024 |

---

## Informal Reasoning - Implicit Social Reasoning (Theory of Mind)

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âŒ MISSING | - | Theory of mind in large language models vs children aged 7-10 | CoNLL 2023 |
| âŒ MISSING | - | FANToM: A benchmark for stress-testing machine theory of mind | EMNLP 2023 |
| âŒ MISSING | - | Neural theory-of-mind? On the limits of social intelligence in large LMs | EMNLP 2022 |
| ğŸ“‹ TO-READ | 2406.14737 | Dissecting the Ullman Variations with a SCALPEL | arXiv |
| ğŸ“‹ TO-READ | 2302.08399 | Large language models fail on trivial alterations to theory-of-mind tasks | arXiv |
| âŒ MISSING | - | Evaluating large language models in theory of mind tasks | PNAS 2024 |
| âŒ MISSING | - | Clever hans or neural theory of mind? Stress testing social reasoning | EACL 2024 |
| ğŸ“‹ TO-READ | 2410.13648 | SimpleToM: Exposing the Gap between Explicit ToM Inference | arXiv |
| âŒ MISSING | - | Hi-ToM: A benchmark for evaluating higher-order theory of mind | EMNLP 2023 |
| ğŸ“‹ TO-READ | 2310.03051 | How FaR Are Large Language Models From Agents with Theory-of-Mind? | arXiv |
| âŒ MISSING | - | Testing theory of mind in large language models and humans | Nature Human Behaviour 2024 |
| âŒ MISSING | - | Minding Language Models' (Lack of) Theory of Mind: Belief Tracker | ACL 2023 |
| âŒ MISSING | - | Artificial Intelligence and the Illusion of Understanding: Systematic Review | Cyberpsych 2025 |
| âŒ MISSING | - | Towards Dynamic Theory of Mind: Evaluating LLM Adaptation | ACL 2025 |
| âŒ MISSING | - | EmoBench: Evaluating the Emotional Intelligence of Large Language Models | ACL 2024 |
| ğŸ“‹ TO-READ | 2502.04424 | EmoBench-M: Benchmarking Emotional Intelligence for Multimodal LLMs | arXiv |
| âŒ MISSING | - | Can LLMs Reason Like Humans? Assessing ToM for Open-Ended Questions | CIKM 2024 |
| âŒ MISSING | - | The Emotional Intelligence of the GPT-4 Large Language Model | Psychol Russ 2024 |
| âŒ MISSING | - | Multilingual Language Models are not Multicultural: Emotion | ACL 2023 WASSA |
| ğŸ“‹ TO-READ | 2406.04428 | MoralBench: Moral Evaluation of LLMs | arXiv |
| âŒ MISSING | - | "As an AI Language Model," Norm Inconsistency in LLM Decision-Making | AIES 2024 |
| ğŸ“‹ TO-READ | 2402.01719 | Measuring Moral Inconsistencies in Large Language Models | arXiv |
| ğŸ“‹ TO-READ | 2309.13356 | Probing the moral development of large language models | arXiv |
| âŒ MISSING | - | Ethical reasoning and moral value alignment depend on language | ACL 2024 LREC |
| ğŸ“‹ TO-READ | 2404.02934 | GreedLlama: Performance of financial value-aligned LLMs | arXiv |
| ğŸ“‹ TO-READ | 2502.20490 | EgoNormia: Benchmarking Physical Social Norm Understanding | arXiv |
| ğŸ“‹ TO-READ | 2410.07304 | The Moral Turing Test: Evaluating Human-LLM Alignment | arXiv |
| âŒ MISSING | - | The moral machine experiment on large language models | Royal Society |
| âŒ MISSING | - | Investigating machine moral judgement through the Delphi experiment | Nature Machine Intelligence 2025 |

---

## Informal Reasoning - Explicit Social Reasoning

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âŒ MISSING | - | Theory of mind for multi-agent collaboration via large language models | EMNLP 2023 |
| âŒ MISSING | - | SocialEval: Evaluating social intelligence of large language models | ACL 2025 |
| âŒ MISSING | - | Hypothetical minds: Scaffolding theory of mind for multi-agent tasks | ICLR 2025 |
| âŒ MISSING | - | Large language model based multi-agents: A survey | IJCAI 2024 |
| ğŸ“‹ TO-READ | 2402.03578 | LLM multi-agent systems: Challenges and open problems | arXiv |
| ğŸ“‹ TO-READ | 2404.16698 | Cooperate or collapse: Emergence of sustainable cooperation | NeurIPS 2024 |
| âŒ MISSING | - | Building cooperative embodied agents modularly with LLMs | ICLR 2024 |
| ğŸ“‹ TO-READ | 2310.03903 | LLM-Coordination: Evaluating Multi-agent Coordination Abilities | arXiv |
| âŒ MISSING | - | Why Do Multiagent Systems Fail? | ICLR 2025 Workshop |
| âŒ MISSING | - | On the resilience of multi-agent systems with malicious agents | CoRR 2024 |
| ğŸ“‹ TO-READ | 2503.11926 | Monitoring Reasoning Models for Misbehavior | arXiv |
| ğŸ“‹ TO-READ | 2311.08562 | Magic: Investigation of LLM multi-agent cognition | EMNLP 2024 |

---

## Formal Reasoning - Logic in Natural Languages

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âœ… DONE | 2309.12288 | The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A" | ICLR 2024 |
| ğŸ“‹ TO-READ | 2312.03633 | Exploring the Reversal Curse in BERT and GPT-Based LLMs | Patterns 2024 |
| ğŸ“‹ TO-READ | 2403.13799 | Reverse Training to Nurse the Reversal Curse | COLM 2024 |
| ğŸ“‹ TO-READ | 2402.01453 | The Queen of England is not England's Queen | EACL 2024 |
| âŒ MISSING | - | Exploring Reversal Mathematical Reasoning Ability for LLMs | ACL 2024 |
| ğŸ“‹ TO-READ | 2403.00758 | Mitigating Reversal Curse via Semantic-aware Permutation Training | ACL 2024 |
| ğŸ“‹ TO-READ | 2311.07468 | An Analysis and Mitigation of the Reversal Curse | EMNLP 2024 |
| ğŸ“‹ TO-READ | 2310.10322 | Untying the Reversal Curse via Bidirectional Language Model Editing | arXiv |
| âŒ MISSING | - | Rethinking the Reversal Curse of LLMs: Human Knowledge Reversal | EMNLP 2024 |
| ğŸ“‹ TO-READ | 2410.18808 | Delving into the Reversal Curse: How Far Can LLMs Generalize? | NeurIPS 2024 |
| ğŸ“‹ TO-READ | 2405.04669 | Towards a Theoretical Understanding of the 'Reversal Curse' | NeurIPS 2024 |
| ğŸ“‹ TO-READ | 2411.16353 | The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C | arXiv |
| ğŸ“‹ TO-READ | 2502.13913 | How Do LLMs Perform Two-Hop Reasoning in Context? | arXiv |
| ğŸ“‹ TO-READ | 2403.02615 | Exploring Limitations in Compositional Relation Reasoning | COLM 2024 |
| âœ… DONE | 2305.18654 | Faith and Fate: Limits of Transformers on Compositionality | NeurIPS 2023 |
| ğŸ“‹ TO-READ | 2405.06680 | Exploring the Compositional Deficiency in Mathematical Reasoning | EMNLP 2024 |
| âŒ MISSING | 1905.10044 | BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions | NAACL 2019 |
| ğŸ“‹ TO-READ | 2401.00757 | LogicAsker: Evaluating Logical Reasoning Ability of LLMs | EMNLP 2024 |
| ğŸ“‹ TO-READ | 2306.12567 | Evaluating LLMs with NeuBAROCO: Syllogistic Reasoning | NALOMA IV |
| ğŸ“‹ TO-READ | 2310.05163 | An Investigation of LLMs' Inefficacy in Understanding Converse Relations | EMNLP 2023 |
| ğŸ“‹ TO-READ | 2402.10735 | Assessing the Reasoning Abilities of ChatGPT in Claim Verification | arXiv |
| ğŸ“‹ TO-READ | 2406.12158 | LLMs Are Prone to Fallacies in Causal Inference | EMNLP 2024 |
| ğŸ“‹ TO-READ | 2410.16502 | Rulebreakers Challenge: Blind Spot in Formal Logic | arXiv |
| ğŸ“‹ TO-READ | 2402.11051 | LLMs Fall Short: Complex Relationships in Detective Narratives | ACL 2024 |
| ğŸ“‹ TO-READ | 2410.01748 | Not All LLM Reasoners Are Created Equal | arXiv |
| ğŸ“‹ TO-READ | 2407.15720 | Do Large Language Models Have Compositional Ability? | COLM 2024 |
| ğŸ“‹ TO-READ | 2402.14328 | Understanding and Patching Compositional Reasoning in LLMs | ACL 2024 |
| ğŸ“‹ TO-READ | 2411.16679 | Do LLMs Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts? | ACL 2024 |
| ğŸ“‹ TO-READ | 2402.01805 | Enhancing Logical Reasoning through Graph-based Synthetic Data | arXiv |
| ğŸ“‹ TO-READ | 2408.15778 | LogicGame: Benchmarking Rule-Based Reasoning Abilities | ACL 2024 |
| ğŸ“‹ TO-READ | 2402.11442 | Can LLMs Reason with Rules? Logic Scaffolding | ACL 2024 |
| ğŸ“‹ TO-READ | 2408.08978 | See What LLMs Cannot Answer: Self-Challenge Framework | COLM 2024 |

---

## Formal Reasoning - Logic in Benchmarks

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| ğŸ“‹ TO-READ | 2309.03882 | Large Language Models Are Not Robust Multiple Choice Selectors | ICLR 2024 |
| ğŸ“‹ TO-READ | 2402.01781 | When benchmarks are targets: Sensitivity of leaderboards | ACL 2024 |
| ğŸ“‹ TO-READ | 2406.19470 | Changing Answer Order Can Decrease MMLU Accuracy | arXiv |
| ğŸ“‹ TO-READ | 2402.08939 | Premise Order Matters in Reasoning with Large Language Models | ICML 2024 |
| ğŸ“‹ TO-READ | 2410.23884 | Failure Modes of LLMs for Causal Reasoning on Narratives | arXiv |
| âœ… DONE | 2406.11050 | A Peek into Token Bias: LLMs Are Not Yet Genuine Reasoners | EMNLP 2024 |
| âœ… DONE | 2410.05229 | GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning | arXiv |
| âœ… DONE | 2307.02477 | Reasoning or Reciting? Counterfactual Tasks | NAACL 2024 |
| ğŸ“‹ TO-READ | 2402.19255 | GSM-Plus: Evaluating the Robustness of LLMs as Math Solvers | ACL 2024 |
| ğŸ“‹ TO-READ | 2103.07191 | Are NLP Models really able to Solve Simple Math Word Problems? | NAACL 2021 |
| ğŸ“‹ TO-READ | 2212.10264 | ReCode: Robustness Evaluation of Code Generation Models | ACL 2023 |
| ğŸ“‹ TO-READ | 2402.05980 | Do Large Code Models Understand Programming Concepts? | ICML 2024 |
| ğŸ“‹ TO-READ | 2403.19114 | EvoEval: Evolving Coding Benchmarks via LLM | COLM 2024 |
| ğŸ“‹ TO-READ | 2306.03438 | LLMs of Code Fail at Completing Code with Potential Bugs | NeurIPS 2023 |
| ğŸ“‹ TO-READ | 2305.15507 | The Larger They Are, the Harder They Fail: Identifier Swaps | ACL 2023 |
| ğŸ“‹ TO-READ | 2404.01535 | Syntactic Robustness for LLM-based Code Generation | arXiv |
| ğŸ“‹ TO-READ | 2406.11020 | RUPBench: Benchmarking Reasoning Under Perturbations | arXiv |
| ğŸ“‹ TO-READ | 2401.09395 | Evaluating LLMs' Math and Coding via Ontology-guided Interventions | arXiv |
| ğŸ“‹ TO-READ | 2310.01991 | Fill in the Blank: Backward Reasoning in Math Word Problems | arXiv |
| ğŸ“‹ TO-READ | 2502.06453 | MATH-Perturb: Benchmarking LLMs' Math Reasoning against Perturbations | arXiv |
| ğŸ“‹ TO-READ | 2505.20296 | Reasoning LLMs are Wandering Solution Explorers | arXiv |
| âœ… DONE | 2506.06941 | The Illusion of Thinking | arXiv |
| âœ… DONE | 2506.09250 | Comment on The Illusion of Thinking | arXiv |
| âœ… DONE | 2506.18880 | OMEGA: Can LLMs Reason Outside the Box in Math? | arXiv |
| ğŸ“‹ TO-READ | 2507.13337 | FormulaOne: Measuring the Depth of Algorithmic Reasoning | arXiv |

---

## Formal Reasoning - Arithmetic and Mathematics

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| ğŸ“‹ TO-READ | 2412.18626 | Why Do Large Language Models (LLMs) Struggle to Count Letters? | arXiv |
| âœ… DONE | 2507.07313 | Frontier LLMs Still Struggle with Simple Reasoning Tasks | arXiv |
| ğŸ“‹ TO-READ | 2410.19730 | Counting Ability of LLMs and Impact of Tokenization | arXiv |
| ğŸ“‹ TO-READ | 2405.20131 | Language Models Need Inductive Biases to Count Inductively | ICLR 2025 |
| ğŸ“‹ TO-READ | 2410.14166 | LLM The Genius Paradox: Word-based Counting Problems | arXiv |
| ğŸ“‹ TO-READ | 2407.15160 | When Can Transformers Count to n? | arXiv |
| ğŸ“‹ TO-READ | 2405.11357 | Large Language Models Lack Understanding of Character Composition | arXiv |
| âŒ MISSING | - | LLMs Can Not Perform Well in Understanding and Manipulating at Char/Word Levels | EMNLP 2024 |
| âŒ MISSING | - | Can Neural Networks Do Arithmetic? A Survey | Applied Sciences 2024 |
| ğŸ“‹ TO-READ | 2403.19346 | Large Language Models Are Unconscious of Unreasonability in Math | arXiv |
| âŒ MISSING | - | Putnam-AXIOM: A Functional and Static Benchmark for Higher Level Math | OpenReview |
| ğŸ“‹ TO-READ | 2406.17681 | VarBench: Robust Language Model Benchmarking | EMNLP 2024 |
| âœ… DONE | 2406.02061 | Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown | arXiv |
| âŒ MISSING | - | Rationales for Answers to Simple Math Word Problems Confuse LLMs | ACL 2024 |
| ğŸ“‹ TO-READ | 2406.09072 | Living in the Moment: Can LLMs Grasp Co-Temporal Reasoning? | ACL 2024 |
| ğŸ“‹ TO-READ | 2501.02825 | Randomly Sampled Language Reasoning Problems Reveal Limits of LLMs | arXiv |
| ğŸ“‹ TO-READ | 2410.18921 | From Blind Solvers to Logical Thinkers | arXiv |
| ğŸ“‹ TO-READ | 2304.02015 | How well do Large Language Models perform in Arithmetic tasks? | arXiv |
| ğŸ“‹ TO-READ | 2410.13857 | How Numerical Precision Affects Mathematical Reasoning | arXiv |
| ğŸ“‹ TO-READ | 2406.02356 | Language Models Do Hard Arithmetic Easily and Easy Arithmetic Hardly | ACL 2024 |
| ğŸ“‹ TO-READ | 2410.15580 | Language Models are Symbolic Learners in Arithmetic | arXiv |
| ğŸ“‹ TO-READ | 2406.06576 | OccamLLM: Fast and Exact Language Model Arithmetic | NeurIPS 2024 |
| ğŸ“‹ TO-READ | 2309.03241 | GPT Can Solve Mathematical Problems Without a Calculator | arXiv |
| ğŸ“‹ TO-READ | 2406.05055 | Robustness Assessment with Missing and Contradictory Conditions | arXiv |
| ğŸ“‹ TO-READ | 2403.05845 | Reverse That Number! Decoding Order Matters in Arithmetic | arXiv |
| ğŸ“‹ TO-READ | 2402.03822 | RevOrder: A Novel Method for Enhanced Arithmetic in LMs | arXiv |
| âœ… DONE | 2410.21272 | Arithmetic Without Algorithms: Language Models Solve Math with Heuristics | ICLR 2025 |
| ğŸ“‹ TO-READ | 2306.16636 | CMATH: Can Your Language Model Pass Chinese Elementary School Math? | arXiv |
| ğŸ“‹ TO-READ | 2502.11574 | Large Language Models and Mathematical Reasoning Failures | arXiv |
| ğŸ“‹ TO-READ | 2410.09988 | HARDMath: A Benchmark Dataset for Challenging Applied Mathematics | arXiv |
| ğŸ“‹ TO-READ | 2502.01612 | Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization | arXiv |

---

## Embodied Reasoning - 1D Text-Based Physical Reasoning

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âŒ MISSING | - | Prost: Physical reasoning about objects through space and time | ACL 2021 |
| âŒ MISSING | - | TEXT2AFFORD: Probing Object Affordance Prediction from Text | CoNLL 2024 |
| âŒ MISSING | - | A Multi-layered Approach to Physical Commonsense Understanding (Italian) | COLING 2024 |
| âŒ MISSING | - | ChatGPT and the frustrated Socrates | Physics Education 2023 |
| âŒ MISSING | - | Things not written in text: Exploring spatial commonsense from visual signals | ACL 2022 |
| âŒ MISSING | - | POSQA: Probe the World Models of LLMs with Size Comparisons | EMNLP 2023 |
| âŒ MISSING | - | Probing physical reasoning with Counter-Commonsense context | ACL 2023 |
| âŒ MISSING | - | NEWTON: Are Large Language Models Capable of Physical Reasoning? | EMNLP 2023 |
| ğŸ“‹ TO-READ | 2502.12054 | PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning | arXiv |
| ğŸ“‹ TO-READ | 2502.00334 | UGPhysics: Undergraduate Physics Reasoning with LLMs | arXiv |
| ğŸ“‹ TO-READ | 2312.04613 | Testing LLM performance on the Physics GRE | arXiv |
| ğŸ“‹ TO-READ | 2504.16074 | PHYBench: Holistic Evaluation of Physical Perception and Reasoning | arXiv |
| ğŸ“‹ TO-READ | 2507.04766 | ABench-Physics: Benchmarking Physical Reasoning in LLMs | arXiv |
| ğŸ“‹ TO-READ | 2502.15815 | Theoretical Physics Benchmark (TPBench) | arXiv |
| ğŸ“‹ TO-READ | 2412.00821 | Improving Physics Reasoning Using Mixture of Refinement Agents | arXiv |
| âŒ MISSING | - | Structured chemistry reasoning with large language models | ICML 2024 |
| ğŸ“‹ TO-READ | 2502.15224 | Auto-Bench: Automated Benchmark for Scientific Discovery in LLMs | arXiv |

---

## Embodied Reasoning - 2D Perception-Based Physical Reasoning

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âŒ MISSING | - | Core knowledge deficits in multi-modal language models | ICML 2025 |
| âŒ MISSING | - | Breaking common sense: WHOOPS! A vision-and-language benchmark | ICCV 2023 |
| âŒ MISSING | - | Rome: Evaluating pre-trained VLMs on reasoning beyond visual common sense | EMNLP 2023 |
| âŒ MISSING | - | Vision language models are blind | ACCV 2024 |
| âŒ MISSING | - | Visual spatial reasoning | TACL 2023 |
| âŒ MISSING | - | Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning? | NeurIPS 2024 |
| âŒ MISSING | - | Understanding the limits of VLMs through the lens of the binding problem | NeurIPS 2024 |
| âŒ MISSING | 2503.02199 | Words or Vision: Do Vision-Language Models Have Blind Faith in Text? | arXiv |
| âŒ MISSING | - | Large Language Models Are Challenged by Habitat-Centered Reasoning | EMNLP 2024 |
| âŒ MISSING | - | Visual cognition in multimodal large language models | Nature Machine Intelligence 2025 |
| âŒ MISSING | - | Learning the effects of physical actions in a multi-modal environment | EACL 2023 |
| ğŸ“‹ TO-READ | 2412.08619 | Synthetic Vision: Training Vision-Language Models to Understand Physics | arXiv |
| âŒ MISSING | - | PhysBench: Benchmarking and Enhancing VLMs for Physical World Understanding | ICLR 2025 |
| âŒ MISSING | - | Physion: Evaluating physical prediction from vision in humans and machines | NeurIPS 2021 |
| âŒ MISSING | - | Craft: A benchmark for causal reasoning about forces and interactions | ACL 2022 |
| âŒ MISSING | - | MM-PhyQA: Multimodal physics question-answering with multi-image CoT | PAKDD 2024 |
| âŒ MISSING | 2505.15929 | PhyX: Does Your Model Have the "Wits" for Physical Reasoning? | arXiv |
| ğŸ“‹ TO-READ | 2411.08027 | Llmphy: Complex physical reasoning using LLMs and world models | arXiv |
| âŒ MISSING | - | Exploring Failure Cases in Multimodal Reasoning About Physical Dynamics | AAAI 2024 |
| âŒ MISSING | - | On Inherent 3D Reasoning of VLMs in Indoor Scene Layout Design | OpenReview |
| ğŸ“‹ TO-READ | 2409.14277 | Can-Do! A Dataset for Embodied Planning with Large Multimodal Models | arXiv |
| âŒ MISSING | - | BALROG: Benchmarking agentic LLM and VLM reasoning on games | ICLR 2025 |
| ğŸ“‹ TO-READ | 2505.05405 | DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning | arXiv |

---

## Embodied Reasoning - 3D Real-World Physical Reasoning

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| âŒ MISSING | - | Do as I can, not as I say: Grounding language in robotic affordances | CoRL 2022 |
| âŒ MISSING | - | Embodied agent interface: Benchmarking LLMs for embodied decision making | NeurIPS 2024 |
| âŒ MISSING | - | Deploying and evaluating LLMs to program service mobile robots | IEEE 2024 |
| âŒ MISSING | - | Language models as zero-shot planners: Extracting actionable knowledge | ICML 2022 |
| âŒ MISSING | - | RobotGPT: Robot manipulation learning from ChatGPT | IEEE 2024 |
| ğŸ“‹ TO-READ | 2502.14669 | AlphaMaze: Enhancing LLMs' Spatial Intelligence via GRPO | arXiv |
| ğŸ“‹ TO-READ | 2410.23242 | A little less conversation: Physical common-sense in a 3D embodied environment | arXiv |
| ğŸ“‹ TO-READ | 2310.13065 | Creative robot tool use with large language models | arXiv |
| âŒ MISSING | - | SpatialVLM: Endowing vision-language models with spatial reasoning | CVPR 2024 |
| ğŸ“‹ TO-READ | 2410.15863 | Task-oriented robotic manipulation with vision language models | arXiv |
| âŒ MISSING | - | Code as policies: Language model programs for embodied control | ICRA 2023 |
| âŒ MISSING | - | BadRobot: Manipulating embodied LLMs in the physical world | ICLR 2025 |

---

## General/Case-by-Case Reasoning Failure Studies

| Status | arXiv ID | Title | Venue |
|--------|----------|-------|-------|
| ğŸ“‹ TO-READ | 2405.19616 | Easy Problems That LLMs Get Wrong | arXiv |
| âŒ MISSING | - | Reasoning with Transformer-based Models: Deep Learning, but Shallow Reasoning | AKBC 2022 |
| ğŸ“‹ TO-READ | 2302.03494 | A Categorical Archive of ChatGPT Failures | arXiv |

---

## Summary Statistics

| Status | Count |
|--------|-------|
| âœ… DONE (Already Analyzed) | ~20 |
| ğŸ“‹ TO-READ (Issues #48-54) | ~120 |
| âŒ MISSING (Issue #55) | ~87 |
| **Total from Survey** | ~227 |

---

## Tracking Issues

| Issue | Category | Status |
|-------|----------|--------|
| [#47](https://github.com/Proteusiq/unthinking/issues/47) | Survey Paper Analysis | CLOSED |
| [#48](https://github.com/Proteusiq/unthinking/issues/48) | Cognitive Skills & Biases | OPEN |
| [#49](https://github.com/Proteusiq/unthinking/issues/49) | Theory of Mind & Social | OPEN |
| [#50](https://github.com/Proteusiq/unthinking/issues/50) | Logic & Compositional | OPEN |
| [#51](https://github.com/Proteusiq/unthinking/issues/51) | Benchmark Robustness | OPEN |
| [#52](https://github.com/Proteusiq/unthinking/issues/52) | Arithmetic & Math | OPEN |
| [#53](https://github.com/Proteusiq/unthinking/issues/53) | Embodied & Physical | OPEN |
| [#54](https://github.com/Proteusiq/unthinking/issues/54) | General Failure Studies | OPEN |
| [#55](https://github.com/Proteusiq/unthinking/issues/55) | MISSING Papers | OPEN |
